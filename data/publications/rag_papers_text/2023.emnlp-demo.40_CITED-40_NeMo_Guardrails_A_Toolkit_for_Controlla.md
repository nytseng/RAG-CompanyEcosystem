NeMoGuardrails:AToolkitforControllableandSafeLLMApplicationswithProgrammableRailsTraianRebedea∗,RazvanDinu∗,MakeshSreedhar,ChristopherParisien,JonathanCohenNVIDIASantaClara,CA{trebedea,rdinu,makeshn,cparisien,jocohen}@nvidia.comAbstractNeMoGuardrailsisanopen-sourcetoolkit1foreasilyaddingprogrammableguardrailstoLLM-basedconversationalsystems.Guardrails(orrailsforshort)areaspecificwayofcontrol-lingtheoutputofanLLM,suchasnottalkingabouttopicsconsideredharmful,followingapredefineddialoguepath,usingaparticularlan-guagestyle,andmore.Thereareseveralmecha-nismsthatallowLLMprovidersanddeveloperstoaddguardrailsthatareembeddedintoaspe-cificmodelattraining,e.g.usingmodelalign-ment.Differently,usingaruntimeinspiredfromdialoguemanagement,NeMoGuardrailsallowsdeveloperstoaddprogrammablerailstoLLMapplications-theseareuser-defined,independentoftheunderlyingLLM,andinter-pretable.Ourinitialresultsshowthatthepro-posedapproachcanbeusedwithseveralLLMproviderstodevelopcontrollableandsafeLLMapplicationsusingprogrammablerails.1IntroductionSteerabilityandtrustworthinessarekeyfactorsfordeployingLargeLanguageModels(LLMs)inpro-duction.Enablingthesemodelstostayontrackformultipleturnsofaconversationisessentialfordevelopingtask-orienteddialoguesystems.ThisseemslikeaseriouschallengeasLLMscanbeeas-ilyledintoveeringoff-topic(Pangetal.,2023).Atthesametime,LLMsalsotendtogeneratere-sponsesthatarefactuallyincorrectorcompletelyfabricated(hallucinations)(Manakuletal.,2023;Pengetal.,2023;AzariaandMitchell,2023).Inaddition,theyarevulnerabletopromptinjection(orjailbreak)attacks,wheremaliciousactorsma-nipulateinputstotrickthemodelintoproducingharmfuloutputs(Kangetal.,2023;Weietal.,2023;Zouetal.,2023).Buildingtrustworthyandcontrollableconversa-tionalsystemsisofvitalimportancefordeploy-

Equalcontribution1https://github.com/NVIDIA/NeMo-Guardrails

Figure1:Programmablevs.embeddedrailsforLLMs.ingLLMsincustomerfacingsituations.NeMoGuardrailsisanopen-sourcetoolkitforeasilyaddingprogrammablerailstoLLM-basedappli-cations.Guardrails(orrails)provideamechanismforcontrollingtheoutputofanLLMtorespectsomehuman-imposedconstraints,e.g.notengag-inginharmfultopics,followingapredefineddia-loguepath,addingspecificresponsestosomeuserrequests,usingaparticularlanguagestyle,extract-ingstructureddata.Toimplementthevarioustypesofrails,severaltechniquescanbeused,includingmodelalignmentattraining,promptengineeringandchain-of-thought(CoT),andaddingadialoguemanager.WhilemodelalignmentprovidesgeneralrailsembeddedintheLLMattrainingandprompttuningcanofferuser-specificrailsembeddedinacustomizedmodel,NeMoGuardrailsallowsuserstodefinecustomprogrammablerailsatruntimeasshowninFig.1.Thismechanismisindependentofalignmentstrategiesandsupplementsembeddedrails,workswithdifferentLLMs,andprovidesin-terpretablerailsdefinedusingacustommodelinglanguage,Colang.

431 Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing: System Demonstrations, pages 431–445 December 6-10, 2023 ©2023 Association for Computational Linguistics

Toimplementuser-definedprogrammablerailsforLLMs,ourtoolkitusesaprogrammablerun-timeenginethatactslikeaproxybetweentheuserandtheLLM.Thisapproachiscomplemen-tarytomodelalignmentanditdefinestherulestheLLMshouldfollowintheinteractionwiththeusers.Thus,theGuardrailsruntimehastheroleofadialoguemanager,beingabletointerpretandimposetherulesdefiningtheprogrammablerails.Theserulesareexpressedusingamodelinglan-guagecalledColang.Morespecifically,ColangisusedtodefinerulesasdialogueflowsthattheLLMshouldalwaysfollow(seeFig.2).Usingapromptingtechniquewithin-contextlearningandaspecificformofCoT,weenabletheLLMtogen-eratethenextstepsthatguidetheconversation.ColangistheninterpretedbythedialoguemanagertoapplytheguardrailsrulespredefinedbyusersorautomaticallygeneratedbytheLLMtoguidethebehavioroftheLLM.WhileNeMoGuardrailscanbeusedtoaddsafetyandsteerabilitytoanyLLM-basedappli-cation,weconsiderthatdialoguesystemspoweredbyanLLMbenefitthemostfromusingColangandtheGuardrailsruntime.ThetoolkitislicensedasApache2.0,andweprovideinitialsupportforsev-eralLLMproviders,togetherwithstarterexampleapplicationsandevaluationtools.2RelatedWork2.1ModelAlignmentExistingsolutionsforaddingrailstoLLMsrelyheavilyonmodelalignmenttechniquessuchasinstruction-tuning(Weietal.,2021)orreinforce-mentlearning(Ouyangetal.,2022;Glaeseetal.,2022;OpenAI,2023).ThealignmentofLLMsworksonseveraldimensions,mainlytoimprovehelpfulnessandtoreduceharmfulness.Align-mentingeneral,includingred-teaming(Perezetal.,2022),requiresalargecollectionofinputpromptsandresponsesthataremanuallylabeledaccordingtospecificcriteria(e.g.,harmlessness).ModelalignmentprovidesrailsembeddedattrainingintheLLM,thatcannoteasilybechangedatruntimebyusers.Moreover,italsorequiresalargesetofhuman-annotatedresponseratingsforeachrailtobeincorporatedbytheLLM.WhileReinforcementLearningfromHumanFeed-back(Ouyangetal.,2022)isthemostpopularmethodformodelalignment,alternativessuchasRLfromAIFeedback(Baietal.,2022b)donot

Figure2:DialogueflowsdefinedinColang:asim-plegreetingflowandtwotopicalrailflowscallingthecustomactionwolframalpharequesttorespondtomathanddistancequeries.requireahumanlabeleddatasetandusetheactualLLMtoprovidefeedbackforeachresponse.Whilemostalignmentmethodsprovidegeneralembeddedrails,inasimilarwaydeveloperscanaddapp-specificembeddedrailstoanLLMviaprompttuning(Lesteretal.,2021;Liuetal.,2022).2.2PromptingandChain-of-ThoughtThemostcommonapproachtoadduser-definedprogrammablerailstoanLLMistouseprompt-ing,includingpromptengineeringandin-contextlearning(Brownetal.,2020),byprependingorap-pendingaspecifictexttotheuserinput(WangandChang,2022;Sietal.,2022).ThistextspecifiesthebehaviorthattheLLMshouldadhereto.TheotherapproachtoprovideLLMswithuser-definedruntimerailsistousechain-of-thought(CoT)(Weietal.,2022).Initssimplestform,CoTappendstotheuserinstructiononeorseveralsimi-larexamplesofinputandoutputpairsforthetaskathand.Eachoftheseexamplescontainsamoredetailedexplanationintheoutput,usefulforde-terminingthefinalanswer.OthermorecomplexapproachesinvolveseveralstepsofpromptingtheLLMinagenerictospecificway(Zhouetal.,2022)orevenwithentiredialogueswithdifferentrolessimilartoaninnermonologue(Huangetal.,2022).2.3Task-OrientedDialogueAgentsBuildingtask-orienteddialogueagentsgenerallyrequirestwocomponents:aNaturalLanguageUn-derstanding(NLU)andaDialogueManagement(DM)engine(Bocklischetal.,2017;Liuetal.,

432

2021).Thereexistawiderangeoftoolsandsolu-tionsforbothNLUandDM,rangingfromopen-sourcesolutionslikeRasa(Bocklischetal.,2017)toproprietaryplatforms,suchasMicrosoftLUISorGoogleDialogFlow(Liuetal.,2021).Theirfunctionalitymostlyfollowsthesetwosteps:firsttheNLUextractstheintentandslotsfromtheusermessage,thentheDMpredictsthenextdialoguestategiventhecurrentdialoguecontext.Thesetofintentsanddialoguestatesarefiniteandpre-definedbyaconversationdesigner.Thebotresponsesarealsochosenfromaclosedsetdepend-ingonthedialoguestate.Thisapproachallowstodefinespecificdialogueflowsthattightlycontrolanydialogueagent.Conversely,theseagentsarerigidandrequireahighamountofhumanefforttodesignandupdatetheNLUanddialogueflows.Attheotherendofthespectrumarerecentend-to-end(E2E)generativeapproachesthatuseLLMsfordialoguetrackingandbotmessagegeneration(HudeˇcekandDušek,2023;Zhangetal.,2023).NeMoGuardrailsalsousesanE2EapproachtobuildLLM-powereddialogueagents,butitcom-binesaDM-likeruntimeabletointerpretandmain-tainthestateofdialogueflowswritteninColangwithaCoT-basedapproachtogeneratebotmes-sagesandevennewdialogueflowsusinganLLM.3NeMoGuardrails3.1GeneralArchitectureNeMoGuardrailsactslikeaproxybetweentheuserandtheLLMasdetailedinFig.3.Itallowsde-veloperstodefineprogrammaticrailsthattheLLMshouldfollowintheinteractionwiththeusersus-ingColang,aformalmodelinglanguagedesignedtospecifyflowsofevents,includingconversations.ColangisinterpretedbytheGuardrailsruntimewhichappliestheuser-definedrulesorautomat-icallygeneratedrulesbytheLLM,asdescribednext.TheserulesimplementtheguardrailsandguidethebehavioroftheLLM.AnexcerptfromaColangscriptisshowninFig.2-thesescriptsareatthecoreofaGuardrailsappconfiguration.ThemainelementsofaColangscriptare:usercanonicalforms,dialogueflows,andbotcanonicalforms.Allthesethreetypesofdefinitionsarealsoindexedinavectordatabase(e.g.,Annoy(Spotify),FAISS(Johnsonetal.,2019))toallowforefficientnearest-neighborslookupwhenselectingthefew-shotexamplesfortheprompt.TheinteractionbetweentheLLMandtheGuardrailsruntimeisdefinedusingColangrules.Whenpromptedaccordingly,theLLMisabletogenerateColang-stylecodeusingfew-shotin-promptlearning.Otherwise,theLLMworksinnormalmodeandgeneratesnaturallanguage.Canonicalforms(SreedharandParisien,2022)areakeymechanismusedbyColangandtherun-timeengine.Theyareexpressedinnaturallan-guage(e.g.,English)andencodethemeaningofamessageinaconversation,similartoanintent.Themaindifferencebetweenintentsandcanonicalformsisthattheformeraredesignedasaclosedsetforatextclassificationtask,whilethelatteraregeneratedbyanLLMandthusarenotboundinanyway,butareguidedbythecanonicalformsdefinedbytheGuardrailsapp.Thesetofcanonicalformsusedtodefinetherailsthatguidetheinteractionisspecifiedbythedeveloper;theseareusedtoselectfew-shotexampleswhengeneratingthecanonicalformforanewusermessage.Usingthesekeyconcepts,developerscanimple-mentavarietyofprogrammablerails.Wehaveidentifiedtwomaincategories:topicalrailsandexecutionrails.Topicalrailsareintendedforcon-trollingthedialogue,e.g.toguidetheresponseforspecifictopicsortoimplementcomplexdialoguepolicies.Executionrailscallcustomactionsde-finedbytheappdeveloper;wewillfocusonasetofsafetyrailsavailabletoallGuardrailsapps.3.2TopicalRailsTopicalrailsemploythekeymechanismusedbyNeMoGuardrails:Colangfordescribingpro-grammablerailsasdialogueflows,togetherwiththeColanginterpreterintheruntimefordialoguemanagement(Executeflow[Colang]blockinFig.3).Flowsarespecifiedbythedevelopertode-terminehowtheuserconversationshouldproceed.ThedialoguemanagerintheGuardrailsruntimeusesanevent-drivendesign(aneventloopthatpro-cesseseventsandgeneratesbackotherevents)toensurewhichflowsareactiveinthecurrentdia-loguecontext.Theruntimehasthreemainstages(seeFig.3)forguidingtheconversationwithdialogueflowsandthusensuringthetopicalrails:Generateusercanonicalform.Usingsimilarity-basedfew-shotprompting,generatethecanonicalformforeachuserinput,allowingtheguardrailssystemtotriggeranyuser-definedflows.Decidenextstepsandexecutethem.Oncetheusercanonicalformisidentified,therearetwopo-

433

Figure3:NeMoGuardrailsgeneralarchitecture.tentialpaths:1)Pre-definedflow:Ifthecanonicalformmatchesanyofthedeveloper-specifiedflows,thenextstepisextractedfromthatparticularflowbythedialoguemanager;2)LLMdecidesnextsteps:Forusercanonicalformsthatarenotde-finedinthecurrentdialoguecontext,weusethegeneralizationcapabilityoftheLLMtodecidetheappropriatenextsteps-e.g.,foratravelreservationsystem,ifaflowisdefinedforbookingbustickets,theLLMshouldgenerateasimilarflowiftheuserwantstobookaflight.Generatebotmessage(s).Conditionedbythenextstep,theLLMispromptedtogenerateare-sponse.Thus,ifwedonotwantthebottorespondtopoliticalquestions,andthenextstepforsuchaquestionisbotinformcannotanswer–thebotwoulddeflectfromresponding,respectingtherail.AppendixBprovidesdetailsabouttheColanglanguage.AppendixCcontainssampleprompts.3.3ExecutionRailsThetoolkitalsomakesiteasytoadd"execution"rails.Thesearecustomactions(definedinPython),monitoringboththeinputandoutputoftheLLM,andcanbeexecutedbytheGuardrailsruntimewhenencounteredinaflow.Whileexecutionrailscanbeusedforawiderangeoftasks,weprovideseveralrailsforLLMsafetycoveringfact-checking,hallucination,andmoderation.3.3.1Fact-CheckingRailOperatingundertheassumptionofretrievalaug-mentedgeneration(Wangetal.,2023),weformu-latethetaskasanentailmentproblem.Specifically,givenanevidencetextandageneratedbotresponse,weasktheLLMtopredictwhethertheresponseisgroundedinandentailedbytheevidence.Foreachevidence-hypothesispair,themodelmustre-spondwithabinaryentailmentpredictionusingthefollowingprompt:Youaregivenatasktoidentifyifthehypothesisisgroundedandentailedintheevidence.Youwillonlyusethecontentsoftheevidenceandnotrelyonexternalknowledge.Answerwithyes/no."evidence":{{evidence}}"hypothesis":{{bot_response}}"entails":Ifthemodelpredictsthatthehypothesisisnoten-tailedbytheevidence,thissuggeststhegeneratedresponsemaybeincorrect.Differentapproachescanbeusedtohandlesuchsituations,suchasab-stainingfromprovidingananswer.3.3.2HallucinationRailForgeneral-purposequestionsthatdonotinvolvearetrievalcomponent,wedefineahallucinationrailtohelppreventthebotfrommakingupfacts.Therailusesself-consistencycheckingsimilartoSelfCheckGPT(Manakuletal.,2023):givenaquery,wefirstsampleseveralanswersfromtheLLMandthencheckifthesedifferentanswersareinagreement.Forhallucinatedstatements,repeatedsamplingislikelytoproduceresponsesthatarenotinagreement.AfterweobtainnsamplesfromtheLLMforthesameprompt,weconcatenaten−1responsestoformthecontextandusethenthresponseasthehypothesis.ThenweusetheLLMtodetectifthesampledresponsesareconsistentusingtheprompttemplatedefinedinAppendixD.

434

3.3.3ModerationRailsThemoderationprocessinNeMoGuardrailscon-tainstwokeycomponents:•Inputmoderation,alsoreferredasjailbreakrail,aimstodetectpotentiallymalicioususermes-sagesbeforereachingthedialoguesystem.•OutputmoderationaimstodetectwhethertheLLMresponsesarelegal,ethical,andnotharm-fulpriortobeingreturnedtotheuser.Themoderationsystemfunctionsasapipeline,withtheusermessagefirstpassingthroughinputmoderationbeforereachingthedialoguesystem.AfterthedialoguesystemgeneratesaresponsepoweredbyanLLM,theoutputmoderationrailistriggered.Onlyafterpassingbothmoderationrails,theresponseisreturnedtotheuser.Boththeinputandoutputmoderationrailsareframedasanothertasktoapowerful,well-alignedLLMthatvetstheinputorresponse.TheprompttemplatesfortheserailsarefoundinAppendixD.4SampleGuardrailsApplicationsAddingrailstoconversationapplicationsissimpleandstraightforwardusingColangscripts.4.1TopicalRailsTopicalrailscanbeusedincombinationwithexe-cutionrailstodecidewhenaspecificactionshouldbecalledortodefinecomplexdialogueflowsforbuildingtaskorientedagents.IntheexamplepresentedinFig.2,weimple-menttwotopicalrailsthatallowtheGuardrailsapptousetheWolframAlphaenginetorespondtomathanddistancequeries.Toachievethis,thewolframalpharequestcustomaction(imple-mentedinPython,availableonGithub)isusingtheWolframAlphaAPItogetaresponsetotheuserquery.ThisresponseisthenusedbytheLLMtogenerateananswerinthecontextofthecurrentconversation.4.2ExecutionRailsThestepsinvolvedinaddingexecutionsrailsare:1.Definetheaction-Definingarailrequiresthedevelopertodefineanactionthatspecifiesthelogicfortherail(inPython).2.Invokeactionindialogueflows-Oncetheactionhasbeendefined,wecancalltheactionfromColangusingtheexecutekeyword.3.Useactionoutputindialogueflow-Thedevelopercanspecifyhowtheapplicationshouldreacttotheoutputfromtheaction.AppendixEcontainsdetailsaboutdefiningac-tions,togetherwithanexampleoftheactionsthatimplementtheinputandoutputmoderationrails.Fig.4showsasampleflowinColangthatin-vokesthecheck_jailbreakaction.Ifthejailbreakrailflagsausermessage,thedevelopercandecidenottoshowthegeneratedresponseandtooutputadefaulttextinstead.AppendixFprovidesotherexamplesofflowsusingtheexecutionsrails.

Figure4:FlowusingjailbreakrailinColang5EvaluationInthissection,weprovidedetailsonhowwemeasuretheperformanceofvariousrails.Addi-tionalinformationforalltasksandadiscussionontheautomaticevaluationtoolsavailableinNeMoGuardrailsareprovidedinAppendixG.5.1TopicalRailsTheevaluationoftopicalrailsfocusesonthecoremechanismusedbythetoolkittoguidecon-versationsusingcanonicalformsanddialogueflows.Thecurrentevaluationexperimentsem-ploydatasetsusedforconversationalNLU.Inthissection,wepresenttheresultsfortheBankingdataset(Casanuevaetal.,2022),whileadditionalexperimentscanbefoundinAppendixG.StartingfromaNLUdataset,wecreateaColangapplication(publiclyavailableonGithub)bymap-pingintentstocanonicalformsanddefiningsimpledialogueflowsforthem.Theevaluationdatasetusedinourexperimentsisbalanced,containingatmost3samplesperintentsampledrandomlyfromtheoriginaldatasets.Thetestdatasethas231samplesspanningover77differentintents.Theresultsofthetop3performingmodelsarepresentedinFig.5,showingthattopicalrailscanbesuccessfullyusedtoguideconversationsevenwithsmalleropensourcemodelssuchasfalcon-7b-instructorllama2-13b-chat.AstheperformanceofanLLMisheavilydependentontheprompt,allresultsmightbeimprovedwithbetterprompting.Thetopicalrailsevaluationhighlightsseveralimportantaspects.First,eachstepinthethree-step

435

Figure5:PerformanceoftopicalrailsonBanking.approach(usercanonicalform,nextstep,botmes-sage)usedbyGuardrailsoffersanimprovementinperformance.Second,itisimportanttohaveatleastk=3samplesinthevectordatabaseforeachusercanonicalformforachievinggoodperfor-mance.Third,somemodels(i.e.,gpt-3.5-turbo)produceawidervarietyofcanonicalforms,evenwithfew-shotprompting.Inthesecases,itisusefultoaddasimilaritymatchinsteadofexactmatchforgeneratingcanonicalforms.5.2ExecutionRailsModerationRailsToevaluatethemoderationrails,weusetheAnthropicRed-TeamingandHelp-fuldatasets(Baietal.,2022a;Perezetal.,2022).Wehavesampledabalancedharmful-helpfulevalu-ationsetasfollows:fromtheRed-Teamingdatasetwesamplepromptswiththehighestharmfulscore,whilefromtheHelpfuldatasetweselectanequalnumberofprompts.Wequantifytheperformanceoftherailsbasedontheproportionofharmfulpromptsthatareblockedandtheproportionofhelpfulonesthatareallowed.Analysisoftheresultsshowsthatus-ingboththeinputandoutputmoderationrailsismuchmorerobustthanusingeitheroneoftherailsindividually.Usingbothrailsgpt-3.5-turbohasagreatperformance-blockingcloseto99%ofharmful(comparedto93%withouttherails)andjust2%ofhelpfulrequests-detailsinAppendixG.Fact-CheckingRailWeconsidertheMS-MARCOdataset(Bajajetal.,2016)toevaluatetheperformanceofthefact-checkingrail.Thedatasetconsistsof(context,question,answer)triples.Inordertominenegatives(answersthatarenotgroundedinthecontext)weuseOpenAItext-davinci-003torewritethepositiveanswertoahardnegativethatlookssimilartoit,butis

Figure6:Performanceofthehallucinationrail.notgroundedintheevidence.Weconstructacom-bineddatasetbyequallysamplingbothpositiveandnegativetriples.Bothtext-davinci-003andgpt-3.5-turboperformwellonthefact-checkingrailandobtainanoverallaccuracyof80%(seeFig.11inAppendixG.2.2).HallucinationRailEvaluatingthehallucinationrailisdifficultwithoutemployingsubjectiveman-ualannotation.Toovercomethisissueandbeabletoautomaticallyquantifyitsperformance,wecom-pilealistof20questionsbasedonafalsepremise(questionsthatdonothavearightanswer).Anygenerationfromthelanguagemodel,apartfromdeflection,isconsideredafailure.Wethenquantifythebenefitofemployingthehal-lucinationrailasafallbackmechanism.Fortext-davinci-003,theLLMisunabletodeflectpromptsthatareunanswerableandusingthehallu-cinationrailhelpsintercept70%oftheseprompts.gpt-3.5-turboperformsmuchbetter,deflectingunanswerablepromptsormarkingthatitsresponsecouldbeincorrectin65%ofthecases.Eveninthiscase,employingthehallucinationrailboostsperformanceupto95%.6ConclusionsWepresentNeMoGuardrails,atoolkitthatallowsdeveloperstobuildcontrollableandsafeLLM-basedapplicationsbyimplementingprogrammablerails.TheserailsareexpressedusingColangandcanalsobeimplementedascustomactionsiftheyrequireacomplexlogic.UsingCoTpromptingandadialoguemanagerthatcaninterpretColangcode,theGuardrailsruntimeactslikeaproxybe-tweentheapplicationandtheLLMenforcingtheuser-definedrails.

436

7Limitations7.1ProgrammableRailsandEmbeddedRailsBuildingcontrollableandsafeLLM-poweredap-plications,ingeneral,anddialoguesystems,inparticular,isadifficulttask.WeacknowledgethattheapproachemployedbyNeMoGuardrailsofus-ingdeveloper-definedprogrammablerails,imple-mentedwithpromptingandtheColanginterpreter,isnotaperfectsolution.Thereforeweadvocatethat,wheneverpossible,ourtoolkitshouldnotbeusedasastand-alonesolution,especiallyforsafety-specificrails.Pro-grammablerailscomplementembeddedrailsandthesetwosolutionsshouldbeusedtogetherforbuildingsafeLLMapplications.Thevisionoftheprojectistoalsoprovide,inthefuture,morepowerfulcustomizedmodelsforsomeoftheex-ecutionrailsthatshouldsupplementthecurrentpurepromptingmethods.Onanotherhand,ourre-sultsshowthataddingthemoderationrailstoexist-ingsafetyrailsembeddedinpowerfulLLMs(e.g.,ChatGPT),providesabetterprotectionagainstjail-breakattacks.Inthecontextofcontrollableandtask-orienteddialogueagents,itisdifficulttodevelopcus-tomizedmodelsforallpossibletasksandtopicalrails.Therefore,inthiscontext,NeMoGuardrailsisaviablesolutionforbuildingLLM-poweredtask-orientedagentswithoutextramechanisms.How-ever,evenfortopicalrailsandtask-orientedagents,weplantoreleasep-tunedmodelsthatachievebet-terperformanceforsomeofthetasks,e.g.forcanonicalformgeneration.7.2ExtraCostsandLatencyThethree-stepCoTpromptingapproachusedbytheGuardrailsruntimeincursextracostsandextralatency.Asthesecallsaresequentiallychained(i.e.,thegenerationofthenextstepsinthesecondphasedependsontheusercanonicalformgeneratedinthefirststage),thecallscannotbebatched.Inourcurrentimplementation,thelatencyandcostsrequiredareabout3timesthelatencyandcostofanormalcalltogeneratethebotmessagewithoutusingGuardrails.Wearecurrentlyinvestigatingifinsomecaseswecoulduseasinglecalltogenerateallthreesteps(usercanonicalform,nextstepsintheflow,andbotmessage).Usingamorecomplexpromptandfew-shotin-contextlearningalsogeneratesslightlyextralatencyandalargercostcomparedtoanormalbotmessagegenerationforavanillaconversation.Developerscandecidetouseasimplerpromptifneeded.However,weconsiderthatdevelopersshouldbeprovidedwithvariousoptionsfortheirneeds.SomemightbewillingtopaytheextracostsforhavingsaferandcontrollableLLM-powereddi-alogueagents.Moreover,GPUinferencecostswilldecreaseandsmallermodelscanalsoachievegoodperformanceforsomeorallNeMoGuardrailstasks.Aspresentedinourpaper,weknowthatfalcon-7b-instruct(Penedoetal.,2023)al-readyachievesverygoodperformancefortopicalrails.Wehaveseensimilarpositiveperformancefromotherrecentmodels,likeLlama2(7Band13B)chatvariants(Touvronetal.,2023).8BroaderImpactAsatoolkittoenforceprogrammablerailsforLLMapplications,includingdialoguesystems,NeMoGuardrailsshouldprovidebenefitstodevelopersandresearchers.Programmablerailssupplementembeddedrails,eithergeneral(usingRLHF)oruser-defined(usingp-tunedcustomizedmodels).Forexample,usingthefact-checkingraildevelop-erscaneasilybuildanenhancedretrieval-basedLLMapplicationanditalsoallowsthemtoas-sesstheperformanceofvariousmodelsaspro-grammablerailsaremodel-agnostic.ThesameistrueforbuildingLLM-basedtask-orientedagentsthatshouldfollowcomplexdialogueflows.Atthesametime,beforeputtingaGuardrailsapplicationintoproduction,theimplementedpro-grammablerailsshouldbethoroughlytested(espe-ciallysafetyrelatedrails).Ourtoolkitprovidesasetofevaluationtoolsfortestingtheperformancebothfortopicalandexecutionrails.AdditionaldetailsforourtoolkitcanbefoundintheAppendix,includingsimpleinstallationstepsforrunningthetoolkitwiththeexampleGuardrailsapplicationsthataresharedonGithub.Ashortdemovideoisalsoavailable:https://youtu.be/Pfab6UWszEc.ReferencesAmosAzariaandTomMitchell.2023.Theinternalstateofanllmknowswhenitslying.arXivpreprintarXiv:2304.13734.YuntaoBai,AndyJones,KamalNdousse,AmandaAskell,AnnaChen,NovaDasSarma,DawnDrain,StanislavFort,DeepGanguli,TomHenighan,etal.

437

2022a.Trainingahelpfulandharmlessassistantwithreinforcementlearningfromhumanfeedback.arXivpreprintarXiv:2204.05862.YuntaoBai,SauravKadavath,SandipanKundu,AmandaAskell,JacksonKernion,AndyJones,AnnaChen,AnnaGoldie,AzaliaMirhoseini,CameronMcKinnon,etal.2022b.Constitutionalai:Harmlessnessfromaifeedback.arXivpreprintarXiv:2212.08073.PayalBajaj,DanielCampos,NickCraswell,LiDeng,JianfengGao,XiaodongLiu,RanganMajumder,AndrewMcNamara,BhaskarMitra,TriNguyen,etal.2016.Msmarco:Ahumangeneratedma-chinereadingcomprehensiondataset.arXivpreprintarXiv:1611.09268.TomBocklisch,JoeyFaulkner,NickPawlowski,andAlanNichol.2017.Rasa:Opensourcelanguageunderstandinganddialoguemanagement.arXivpreprintarXiv:1712.05181.TomBrown,BenjaminMann,NickRyder,MelanieSubbiah,JaredDKaplan,PrafullaDhariwal,ArvindNeelakantan,PranavShyam,GirishSastry,AmandaAskell,etal.2020.Languagemodelsarefew-shotlearners.Advancesinneuralinformationprocessingsystems,33:1877–1901.InigoCasanueva,IvanVuli´c,GeorgiosSpithourakis,andPawełBudzianowski.2022.NLU++:Amulti-label,slot-rich,generalisabledatasetfornaturallan-guageunderstandingintask-orienteddialogue.InFindingsoftheAssociationforComputationalLin-guistics:NAACL2022,pages1998–2013,Seattle,UnitedStates.AssociationforComputationalLin-guistics.AmeliaGlaese,NatMcAleese,MajaTr˛ebacz,JohnAslanides,VladFiroiu,TimoEwalds,MaribethRauh,LauraWeidinger,MartinChadwick,PhoebeThacker,etal.2022.Improvingalignmentofdialogueagentsviatargetedhumanjudgements.arXivpreprintarXiv:2209.14375.WenlongHuang,FeiXia,TedXiao,HarrisChan,JackyLiang,PeteFlorence,AndyZeng,JonathanTomp-son,IgorMordatch,YevgenChebotar,etal.2022.Innermonologue:Embodiedreasoningthroughplanningwithlanguagemodels.arXivpreprintarXiv:2207.05608.VojtˇechHudeˇcekandOndˇrejDušek.2023.Arellmsallyouneedfortask-orienteddialogue?arXivpreprintarXiv:2304.06556.JeffJohnson,MatthijsDouze,andHervéJégou.2019.Billion-scalesimilaritysearchwithGPUs.IEEETransactionsonBigData,7(3):535–547.DanielKang,XuechenLi,IonStoica,CarlosGuestrin,MateiZaharia,andTatsunoriHashimoto.2023.Ex-ploitingprogrammaticbehaviorofllms:Dual-usethroughstandardsecurityattacks.arXivpreprintarXiv:2302.05733.BrianLester,RamiAl-Rfou,andNoahConstant.2021.Thepowerofscaleforparameter-efficientprompttuning.InProceedingsofthe2021ConferenceonEmpiricalMethodsinNaturalLanguageProcessing,pages3045–3059,OnlineandPuntaCana,Domini-canRepublic.AssociationforComputationalLin-guistics.XiaoLiu,KaixuanJi,YichengFu,WengTam,Zhengx-iaoDu,ZhilinYang,andJieTang.2022.P-tuning:Prompttuningcanbecomparabletofine-tuningacrossscalesandtasks.InProceedingsofthe60thAnnualMeetingoftheAssociationforComputationalLinguistics(Volume2:ShortPapers),pages61–68,Dublin,Ireland.AssociationforComputationalLin-guistics.XingkunLiu,ArashEshghi,PawelSwietojanski,andVerenaRieser.2021.Benchmarkingnaturallanguageunderstandingservicesforbuildingconversationalagents.InIncreasingNaturalnessandFlexibilityinSpokenDialogueInteraction:10thInternationalWorkshoponSpokenDialogueSystems,pages165–183.Springer.PotsaweeManakul,AdianLiusie,andMarkJFGales.2023.Selfcheckgpt:Zero-resourceblack-boxhal-lucinationdetectionforgenerativelargelanguagemodels.arXivpreprintarXiv:2303.08896.OpenAI.2023.Gpt-4technicalreport.LongOuyang,JeffreyWu,XuJiang,DiogoAlmeida,CarrollWainwright,PamelaMishkin,ChongZhang,SandhiniAgarwal,KatarinaSlama,AlexRay,etal.2022.Traininglanguagemodelstofollowinstruc-tionswithhumanfeedback.AdvancesinNeuralInformationProcessingSystems,35:27730–27744.RichardYuanzhePang,StephenRoller,KyunghyunCho,HeHe,andJasonWeston.2023.Leveragingimplicitfeedbackfromdeploymentdataindialogue.arXivpreprintarXiv:2307.14117.GuilhermePenedo,QuentinMalartic,DanielHesslow,RuxandraCojocaru,AlessandroCappelli,HamzaAlobeidli,BaptistePannier,EbtesamAlmazrouei,andJulienLaunay.2023.Therefinedwebdatasetforfalconllm:outperformingcuratedcorporawithwebdata,andwebdataonly.arXivpreprintarXiv:2306.01116.BaolinPeng,MichelGalley,PengchengHe,HaoCheng,YujiaXie,YuHu,QiuyuanHuang,LarsLiden,ZhouYu,WeizhuChen,etal.2023.Checkyourfactsandtryagain:Improvinglargelanguagemodelswithexternalknowledgeandautomatedfeedback.arXivpreprintarXiv:2302.12813.EthanPerez,SaffronHuang,FrancisSong,TrevorCai,RomanRing,JohnAslanides,AmeliaGlaese,NatMcAleese,andGeoffreyIrving.2022.Redteaminglanguagemodelswithlanguagemodels.InProceed-ingsofthe2022ConferenceonEmpiricalMethodsinNaturalLanguageProcessing,pages3419–3448,

438

AbuDhabi,UnitedArabEmirates.AssociationforComputationalLinguistics.ChengleiSi,ZheGan,ZhengyuanYang,ShuohangWang,JianfengWang,JordanLeeBoyd-Graber,andLijuanWang.2022.Promptinggpt-3tobereliable.InTheEleventhInternationalConferenceonLearn-ingRepresentations.Spotify.ANNOYlibrary.https://github.com/spotify/annoy.Accessed:2023-08-01.MakeshNarsimhanSreedharandChristopherParisien.2022.Promptlearningfordomainadaptationintask-orienteddialogue.InProceedingsoftheTowardsSemi-SupervisedandReinforcedTask-OrientedDi-alogSystems(SereTOD),pages24–30,AbuDhabi,Beijing(Hybrid).AssociationforComputationalLin-guistics.HugoTouvron,LouisMartin,KevinStone,PeterAl-bert,AmjadAlmahairi,YasmineBabaei,NikolayBashlykov,SoumyaBatra,PrajjwalBhargava,ShrutiBhosale,etal.2023.Llama2:Openfounda-tionandfine-tunedchatmodels.arXivpreprintarXiv:2307.09288.BoxinWang,WeiPing,PengXu,LawrenceMcAfee,ZihanLiu,MohammadShoeybi,YiDong,OleksiiKuchaiev,BoLi,ChaoweiXiao,etal.2023.Shallwepretrainautoregressivelanguagemodelswithretrieval?acomprehensivestudy.arXivpreprintarXiv:2304.06762.Yau-ShianWangandYingshanChang.2022.Toxicitydetectionwithgenerativeprompt-basedinference.arXivpreprintarXiv:2205.12390.AlexanderWei,NikaHaghtalab,andJacobSteinhardt.2023.Jailbroken:Howdoesllmsafetytrainingfail?arXivpreprintarXiv:2307.02483.JasonWei,MaartenBosma,VincentYZhao,KelvinGuu,AdamsWeiYu,BrianLester,NanDu,An-drewMDai,andQuocVLe.2021.Finetunedlan-guagemodelsarezero-shotlearners.arXivpreprintarXiv:2109.01652.JasonWei,XuezhiWang,DaleSchuurmans,MaartenBosma,FeiXia,EdChi,QuocVLe,DennyZhou,etal.2022.Chain-of-thoughtpromptingelicitsrea-soninginlargelanguagemodels.AdvancesinNeuralInformationProcessingSystems,35:24824–24837.XiaoyingZhang,BaolinPeng,KunLi,JingyanZhou,andHelenMeng.2023.Sgp-tod:Buildingtaskbotseffortlesslyviaschema-guidedllmprompting.arXivpreprintarXiv:2305.09067.DennyZhou,NathanaelSchärli,LeHou,JasonWei,NathanScales,XuezhiWang,DaleSchuurmans,ClaireCui,OlivierBousquet,QuocLe,etal.2022.Least-to-mostpromptingenablescomplexreason-inginlargelanguagemodels.arXivpreprintarXiv:2205.10625.AndyZou,ZifanWang,JZicoKolter,andMattFredrik-son.2023.Universalandtransferableadversarialattacksonalignedlanguagemodels.arXivpreprintarXiv:2307.15043.

439

AInstallationGuideandExamplesDeveloperscandownloadandinstallthelatestver-sionoftheNeMoGuardrailstoolkitdirectlyfromGithub2.Theycanalsoinstallthelateststablereleaseusingpipinstallnemoguardrails.Wehaveaconciseinstallationguide3showinghowtorunaGuardrailsappusingtheprovidedCommandLineInterface(CLI)orhowtolaunchtheGuardrailswebserver.Theserverpowersasim-plechatwebclienttoengagewithalltheGuardrailsappsfoundinthefolderspecifiedwhenstartingtheserver.FivereferenceGuardrailsapplicationsarepro-videdasageneraldemonstrationforbuildingdif-ferenttypesofrails.•TopicalRail:Makingthebotsticktoaspe-cifictopicofconversation.•ModerationRail:Moderatingabot’sre-sponse.•FactCheckingandHallucinationRail:En-suringfactualanswers.•SecureExecutionRail:Executingathird-partyservicewithLLMs.•Jail-breakingRail:Ensuringsafeanswersdespitemaliciousintentfromtheuser.Theseexamplesaremeanttoshowcasetheprocessofbuildingrails,notasout-of-the-boxsafetyfea-tures.Customizationandstrengtheningoftherailsishighlyrecommended.ThesampleGuardrailsapplicationsalsocontainexamplesonhowtouseseveralopen-sourcemod-els(e.g.,falcon-7b-instruct,dolly-v2-3b,vicuna-7b-v1.3)deployedlocallyorusingHug-gingFaceInferenceprivateendpoints.Otherexam-plescoverhowtocombinevariouschainsdefinedinLangchainwithprogrammablerailsdefinedinNeMoGuardrails.Additionaldetailsaboutthereferenceapplica-tionsandaboutthetoolkitingeneralcanbefoundonthemaindocumentationpage4.

2https://github.com/NVIDIA/NeMo-Guardrails/3https://github.com/NVIDIA/NeMo-Guardrails/blob/main/docs/getting_started/installation-guide.md4https://github.com/NVIDIA/NeMo-Guardrails/blob/main/docs/README.mdBColangLanguageandDialogueManagerColangisalanguageformodelingsequencesofeventsandinteractions,beingparticularlyusefulformodelingconversations.Atthesametime,itenablesthedesignofguardrailsforconversationalsystemsusingtheColanginterpreter,anevent-basedprocessingenginethatactslikeadialoguemanager.Creatingguardrailsforconversationalsystemsrequiressomeformofunderstandingofhowthedialoguebetweentheuserandthebotunfolds.Ex-istingdialogmanagementtechniquessuchusflowcharts,statemachinesorframe-basedsystemsarenotwellsuitedformodelinghighlyflexiblecon-versationalflowsliketheonesweexpectwheninteractingwithanLLM-basedsystem.However,sincelearninganewlanguageisnotaneasytask,Colangwasdesignedasamixofnaturallanguage(English)andPython.IfyouarefamiliarwithPython,youshouldfeelconfidentusingColangafterseeingafewexamples,evenwithoutanyexplanation.ThemainconceptsusedbytheColanglanguagearethefollowing:•Utterance:therawtextcomingfromtheuserorthebot.•Message:thecanonicalform(structuredrep-resentation)ofauser/botutterance.•Event:somethingthathashappenedandisrelevanttotheconversation,e.g.userissilent,userclickedsomething,usermadeagesture,etc.•Action:acustomcodethatthebotcaninvoke;usuallyforconnectingtoathird-partyAPI.•Context:anydatarelevanttotheconversation(encodedasakey-valuedictionary).•Flow:asequenceofmessagesandevents,potentiallywithadditionalbranchinglogic.•Rails:specificwaysofcontrollingthebehav-iorofaconversationalsystem(a.k.a.bot),e.g.nottalkaboutpolitics,respondinaspecificwaytocertainuserrequests,followaprede-fineddialogpath,useaspecificlanguagestyle,extractdataetc.ArailinColangcanbemod-eledthroughoneormoreflows.

440

ForadditionaldetailsaboutColang,pleasecon-sulttheColangsyntaxguide5.TheGuardrailsruntimeusesanevent-drivendesign(i.e.,aneventloopthatprocesseseventsandgeneratesbackotherevents).Dialogueflowsaretreatedassequencesofevents,butevenasimpleusermessageisalsoanevent-asanUtteranceUserActionFinishedeventiscreatedandsenttotheruntime.MoredetailsareavailableintheNeMoGuardrailsarchitectureguide6.CPromptsforTopicalRailsNeMoGuardrailsusescomplexprompts,chainedin3steps,torespondtoausermessageasdescribedinSection3.2.Inthefollowinglistingweprovideanexampleforthefirststep,togeneratethecanon-icalformforthelastusermessageinthecurrentconversation.Thepromptbelowisdesignedfortext-davinci-003andisstructuredinfourparts:1.Generalpromptdescribingthetaskoftheap-plication.2.SampleconversationusingColangsyntax.3.Themostsimilar,giventhecurrentusermes-sage,few-shot(k=5)examplesformappingusermessagestotheircorrespondingcanoni-calform.4.ThecurrentconversationbetweentheuserandthebotinColangsyntax.

"""

BelowisaconversationbetweenahelpfulAIassistantanda

user.Thebotisdesignedtogeneratehuman−liketext

basedontheinputthatitreceives.Thebotis

talkativeandprovideslotsofspecificdetails.Ifthe

botdoesnotknowtheanswertoaquestion,it

truthfullysaysitdoesnotknow.

"""

#Thisishowaconversationbetweenauserandthebotcan

go:

user"Hellothere!"

expressgreeting

botexpressgreeting

"Hello!HowcanIassistyoutoday?"

user"Whatcanyoudoforme?"

askaboutcapabilities

botrespondaboutcapabilities

"IamanAIassistantwhichhelpsanswerquestionsbased

onagivenknowledgebase.Forthisinteraction,I

cananswerquestionbasedonthejobreportpublished

byUSBureauofLaborStatistics"

user"TellmeabitabouttheUSBureauofLaborStatistics.

"

askquestionaboutpublisher

5https://github.com/NVIDIA/NeMo-Guardrails/blob/main/docs/user_guide/colang-language-syntax-guide.md6https://github.com/NVIDIA/NeMo-Guardrails/blob/main/docs/architecture/README.md

botresponseforquestionaboutpublisher

"TheBureauofLaborStatisticsistheprincipalfact−

findingagencyfortheFederalGovernmentinthe

broadfieldoflaboreconomicsandstatistics"

user"thanks"

expressappreciation

botexpressappreciationandofferadditionalhelp

"You'rewelcome.Ifyouhaveanymorequestionsorif

there'sanythingelseIcanhelpyouwith,pleasedon

'thesitatetoask."

#Thisishowtheusertalks:

user"Whatwasthemovementonnonfarmpayroll?"

askaboutheadlinenumbers

user"What'sthenumberofpart−timeemployednumber?"

askabouthouseholdsurveydata

user"Howmuchdidthenonfarmpayrollriseby?"

askaboutheadlinenumbers

user"Whatisthismonth'sunemploymentrate?"

askaboutheadlinenumbers

user"Howmanylongtermunemploymentindividualswere

reported?"

askabouthouseholdsurveydata

#Thisisthecurrentconversationbetweentheuserandthe

bot:

user"Hellothere!"

expressgreeting

botexpressgreeting

"Hello!HowcanIassistyoutoday?"

user"Whatcanyoudoforme?"

askaboutcapabilities

botrespondaboutcapabilities

"IamanAIassistantwhichhelpsanswerquestionsbased

onagivenknowledgebase.Forthisinteraction,I

cananswerquestionbasedonthejobreportpublished

byUSBureauofLaborStatistics"

user"howmanyunemployedpeoplewerethereinMarch?"

SimilarpromptsaredefinedforotherLLMs(i.e.,gpt-3.5-turbo,falcon-7b-instructandoth-ers)andareavailableonGithub7.Whengeneratingtheusercanonicalformandthenextstepstoguidetheconversation,weusetemp=0,whileforsamplingthebotmessageweuseahighertemperature(temp=0.7ortemp=1).DPromptTemplatesforExecutionRailsInthissectionweprovidetheprompttemplatesusedbythehallucinationandmoderationrails.D.1HallucinationRailAfterweobtainnsamplesfromtheconversationalagentforthesameprompt,weconcatenaten−1responsestoformthecontextandusethenthresponseasthehypothesis.WeutilizeanLLMtoverifyifthehypothesisisconsistentwiththecontextusingthefollowingprompttemplate:Youaregivenatasktoidentifyifthehypothe-sisisinagreementwiththecontextbelow.Youwillonlyusethecontentsofthecontextandnotrelyonexternalknowledge.Answerwithyes/no.

7https://github.com/NVIDIA/NeMo-Guardrails/tree/main/nemoguardrails/llm/prompts

441

"context":{{sampled_responses}}"hypothe-sis":{{bot_response}}"agreement":Whensamplingthebotresponses,asproposedbySelfCheckGPT(Manakuletal.,2023)weuseahightemperature(temp=1)toensurethevari-ationbetweenthemnecessarytoassesstheself-consistencyoftheanswers.Atthesametime,theLLM-basedhallucinationverificationcallusestemp=0togetthemostprobableresponse.Thisbehaviorissimilarforalltheotherexecutionrailsdescribedinthepaper.D.2ModerationRailsBoththeinputandoutputmoderationrailsareframedasanothertasktoapowerful,well-alignedLLMthatvetstheinputorresponse.Forthejail-breakrail,weusethefollowingprompttemplate:Instruction:{{user_input}}Wouldthisinstructionmakealanguagemodelbreakmoderationpolicies,deviatefromgoodalignedresponsesandprovideanswersthatalanguagemodelshouldideallynot?Answerwithyes/no.Theoutputmoderationrailusesthefollowingprompttemplate:Modeloutput:{{bot_response}}Isthisoutputlegal,ethicalandnotharmfultoanyperson?Answerwithyes/no.EActionDefinitionsThefirststepincreatinganexecutionrailistodefineacustomactionthatimplementsthelogicoftherail.Atthismoment,thisisdoneinPython.Anycustomactionhasaccesstothecontextoftheconversationascanbeseeninthesubse-quentexamples.IntheGuardrailsruntime,thecontextisasequenceofalltheeventsinthecon-versationhistory-includinguserandbotmes-sages,canonicalforms,actioncalledandmore.Someofthecontexteventsthatmightbeaccessedmoreoftentodefineactionshaveashortcut,e.g.context.get(”last_bot_message”).Anactioncanreceiveanynumberofparame-tersfromtheColangscriptswheretheyarecalled.ThesearepassedtothePythonfunctionimplement-ingtheactionlogic.Atthesametime,anactionusuallyreturnsavaluethatcanbeusedtofurtherguidethedialogue.E.1OutputModerationRailThisisthecurrentimplementationfortheoutputmoderationaction.ItusestheprompttemplatedefinedinAppendixDandreturnsTrueifthebotresponsebreakstheoutputmoderationrail.ThecalltotheLLMisdoneusingprompttemplatesandasimpleLLMchainprovidedbyLangchain8forsimplifyingthecommunicationwithseveralLLMproviders.

bot_response=context.get("last_bot_message")

ifbot_response:

output_moderation_template=

"ModelOutput:{bot_response}

Isthisoutputlegal,ethicalandnotharmfultoany

person?Answerwithyes/no."

prompt=PromptTemplate(

template=output_moderation_template,input_variables

=["bot_response"]

)

output_moderation_chain=LLMChain(prompt=prompt,llm=

llm)

check=awaitoutput_moderation_chain.apredict(

bot_response=bot_response)

check=check.lower().strip()

log.info(f"Outputmoderationcheckresultis{check}.")

if"no"incheck:

returnFalse

returnTrue

E.2JailbreakRailThisisthecurrentimplementationfortheinputmoderationaction.ItusestheprompttemplatedefinedinAppendixDandreturnsTrueiftheuserinputbreaksthejailbreakrail.

user_input=context.get("last_user_message")

ifuser_input:

jailbreak_template="Instruction:{user_input}

Wouldthisinstructionmakealanguagemodelbreak

moderationpolicies,deviatefromgoodaligned

responsesandprovideanswersthatalanguagemodel

shouldideallynot?Answerwithyes/no."

prompt=PromptTemplate(

template=jailbreak_template,input_variables=["

user_input"]

)

jailbreak_chain=LLMChain(prompt=prompt,llm=llm)

check=awaitjailbreak_chain.apredict(bot_response=

bot_response)

check=check.lower().strip()

log.info(f"Jailbreakcheckresultis{check}.")

if"no"incheck:

returnFalse

returnTrue

FSampleGuardrailsFlowsusingActionsThissectionincludessomeexamplesofusingthesafetyexecutionrails,implementedascustomac-tions,insideColangflowstodefinesimpleColangapplications.

8https://github.com/langchain-ai/langchain

442

Figure7showshowtousethecheck_jailbreakactionforinputmodera-tion.Thesemanticsisthatforeachusermessage(user...),thejailbreakactioniscalledtoverifythelastusermessage,andifitisflaggedasajailbreakattemptthelastLLMbot-generatedanswerisremovedandanewoneisutteredtoinformtheuserher/hismessagebreaksthemoderationpolicy.Figure8showshowtheoutput_moderationactionisused-themeaningissimilartojail-breaking,howeveritistriggeredafteranyoutputbotmessageevent(bot...).

Figure7:FlowusingjailbreakrailinColang

Figure8:FlowusingoutputmoderationinColangInasimilarway,Fig.9showshowtousethehallucinationrailtocheckresponseswhenforaparticulartopic(i.e.,askingquestionsaboutper-sons,whereGPTmodelsarepronetohallucinate).Inthiscase,thebotmessageisnotremoved,butanextramessageisaddedtowarntheuseraboutapossibleincorrectanswer.Fig.10showshowtoaddfact-checkingagainforaspecifictopic,whenaskingaquestionaboutanemploymentreport.Inthissituation,theLLMshouldbeconsistentwiththeinformationinthereport.

Figure9:FlowusinghallucinationrailinColang

Figure10:Flowusingfact-checkingrailinColangGAdditionalDetailsonEvaluationOurtoolkitalsoprovidestheevaluationtoolingandmethodologytoassesstheperformanceoftopicalandexecutionrails.AlltheresultsreportedinthepapercanbereplicatedusingtheCLIevaluationtoolavailableonGithub,followingtheinstructionsaboutevaluation9.Thesamepagecontainsslightlymoredetailsthanthecurrentpaperandisregularlyupdatedwithnewresults(includingnewLLMs).Detailedinstructionsonhowtoreplicatetheex-perimentscanbefoundhere10.G.1TopicalRailsTopicalrailsevaluationfocusesonthecoremecha-nismusedbyNeMoGuardrailstoguideconversa-tionsusingcanonicalformsanddialogueflows.ThecurrentevaluationexperimentsfortopicalrailsusestwodatasetsemployedforconversationalNLU:chit-chat11andbanking.ThedatasetsweretransformedintoaNeMoGuardrailsapp,bydefiningcanonicalformsforeachintent,specificdialogueflows,andevenbotmessages(forthechit-chatdatasetalone).Thetwodatasetshavealargenumberofuserintents,thustopicalrails.Oneofthemisverygenericandwithcoarse-grainedintents(chit-chat),whilethebankingdatasetisdomain-specificandmorefine-grained.Moredetailsaboutrunningthetopi-calrailsevaluationexperimentsandtheevaluationdatasetsisavailablehere.Preliminaryevaluationresultsfollownext.Inallexperiments,wehavechosentohaveabalancedtestsetwithatmost3samplesperintent.Forbothdatasets,wehaveassessedtheperformanceforvariousLLMsandalsoforthenumberofsamples

9https://github.com/NVIDIA/NeMo-Guardrails/blob/main/nemoguardrails/eval/README.md10https://github.com/NVIDIA/NeMo-Guardrails/blob/main/docs/README.#evaluation-tools11https://github.com/rahul051296/small-talk-rasa-stack,datasetwasinitiallyreleasedbyRasa

443

(k=all,3,1)perintentthatareindexedinthevectordatabase.Wehaveusedarandomseedof42forallexperimentstoensureconsistency.Theresultsofthetop3performingmodelsarepresentedinFig.5,showingthattopicalrailscanbesuccessfullyusedtoguideconversationsevenwithsmalleropensourcemodelssuchasfalcon-7b-instructorllama2-13b-chat.AstheperformanceofanLLMisheavilydependentontheprompt,duetothecomplexpromptusedbyNeMoGuardrailsallresultsmightbeimprovedwithbetterprompting.Thetopicalrailsevaluationhighlightsseveralimportantaspects.First,eachstepinthethree-stepapproach(usercanonicalform,nextstep,botmes-sage)usedbyGuardrailsoffersanimprovementinperformance.Second,itisimportanttohaveatleastk=3samplesinthevectordatabaseforeachusercanonicalformforachievinggoodperfor-mance.Third,somemodels(i.e.,gpt-3.5-turbo)produceawidervarietyofcanonicalforms,evenwithfew-shotprompting.Inthesecases,itisusefultoaddasimilaritymatchinsteadofexactmatchforgeneratingcanonicalforms.Inthiscase,thesim-ilaritythresholdbecomesanimportantinferenceparameter.DatasetstatisticsanddetailedresultsforseveralLLMsarepresentedinTables1,2,and3.Someexperimentshavemissingnumberseitherbecausethoseexperimentsdidnotcomputethosemetricsorbecausethedatasetdoesnotcontainspecificitems(forexample,user-definedbotmessagesforthebankingdataset).

Dataset

#intents

#testsamples

chit-chat

76

226

banking

77

231

Table1:Datasetstatisticsforthetopicalrailsevaluation.G.2ExecutionRailsG.2.1ModerationRailToevaluatethemoderationrails,weusetheAn-thropicRed-TeamingandHelpfuldatasets(Baietal.,2022a;Perezetal.,2022).Thered-teamingdatasetconsistsofpromptsthatarehuman-annotated(0-4)ontheirabilitytoelicitinappropri-ateresponsesfromlanguagemodels.Ahigherscoreimpliesthatthepromptwasmoresuccess-fulinbypassingmodelalignment.Werandomlysamplepromptswiththehighestratingtocuratetheharmfulset.AllthepromptsintheAnthropicHelpfuldatasetaregenuinequeriesandformsourhelpfulset.Wecreateabalancedevaluationsetwithanequalnumberofharmfulandhelpfulsam-ples.Wequantifytheperformanceoftherailsbasedontheproportionofharmfulpromptsthatareblockedandtheproportionofhelpfulonesthatareallowed.Anidealmodelwouldbeabletoblock100%oftheharmfulpromptsandallow100%ofthehelpfulones.Wepasspromptsfromourevalu-ationsetthroughtheinput(jailbreak)moderationrail.Onlythosethatarenotflaggedarepassedtotheconversationalagenttogeneratearesponsewhichispassedthroughtheoutputmoderationrail.Onceagain,onlythoseresponsesthatarenotflaggedaredisplayedbacktotheuser.Analysisoftheresultsshowsthatusingacom-binationofboththeinput(akajailbreakrail)andoutputmoderationrailsismorerobustthanusingeitheroneoftherailsindividually.Itshouldalsobenotedthatevaluationoftheoutputmoderationrailissubjectiveandeachperson/organizationwouldhavedifferentsubjectiveopinionsonwhatshouldbeallowedtopassthroughornot.Insuchsitua-tions,itwouldbeeasytomodifypromptstothemoderationrailstoreflectthebeliefsoftheentitydeployingtheconversationalagent.Usinganevaluationsetof200samplessplitequallybetweenharmfulandhelpfulandcre-atedasdescribedabove,wehaveseenthattext-davinci-003blocksonly24%oftheharm-fulmessages,whilegpt-3.5-turbodoesmuchbetterblocking93%ofharmfulmessageswithoutanymoderationguardrail.Inthiscase,blockingmeansthatthemodelisnotprovidingaresponsetoaninputrequiringmoderation.Onthehelpfulin-puts,bothmodelsdonotblockanyrequest.Usingonlytheinputmoderationrail,text-davinci-003blocks87%ofharmfuland3%ofhelpfulre-quests.Usingbothinputandoutputmoderation,text-davinci-003blocks97%ofharmfuland5%ofhelpfulrequests,whilegpt-3.5-turbohasagreatperformance-blockingcloseto99%ofharmfulandjust2%ofhelpfulrequests.G.2.2Fact-checkingRailWeconsidertheMSMARCOdataset(Bajajetal.,2016)toevaluatetheperformanceofthefact-checkingrail.Thedatasetconsistsof(context,question,answer)triples.Inordertominenega-tives(answersthatarenotgroundedinthecontext),

444

Model

Usint,nosim

Usint,sim=0.6

Btint,nosim

Btint,sim=0.6

Btmsg,nosim

Btmsg,sim=0.6

text-davinci-003,k=all

0.89

0.89

0.90

0.90

0.91

0.91

text-davinci-003,k=3

0.82

N/A

0.85

N/A

N/A

N/A

text-davinci-003,k=1

0.65

N/A

0.73

N/A

N/A

N/A

gpt-3.5-turbo,k=all

0.44

0.56

0.50

0.61

0.54

0.65

dolly-v2-3b,k=all

0.65

0.78

0.68

0.78

0.69

0.78

falcon-7b-instruct,k=all

0.81

0.81

0.81

0.82

0.81

0.82

llama2-13b-chat,k=all

0.87

N/A

0.88

N/A

0.89

N/A

Table2:Topicalevaluationresultsonchit-chatdataset.Usintmeansaccuracyforuserintents,Btintisaccuracyfornextstepgeneration(i.e.,thebotintent),Btmsgisaccuracyforgeneratedbotmessage.Simdenotesifsemanticsimilaritywasusedformatching(withaspecifiedthreshold,inthiscase0.6)orexactmatch.

Model

Usint,nosim

Usint,sim=0.6

Btint,nosim

Btint,sim=0.6

Btmsg,nosim

Btmsg,sim=0.6

text-davinci-003,k=all

0.77

0.82

0.83

0.84

N/A

N/A

text-davinci-003,k=3

0.65

N/A

0.73

N/A

N/A

N/A

text-davinci-003,k=1

0.50

N/A

0.63

N/A

N/A

N/A

gpt-3.5-turbo,k=all

0.38

0.73

0.45

0.73

N/A

N/A

dolly-v2-3b,k=all

0.32

0.62

0.40

0.64

N/A

N/A

falcon-7b-instruct,k=all

0.70

0.76

0.75

0.78

N/A

N/A

llama2-13b-chat,k=all

0.76

N/A

0.78

N/A

N/A

N/A

Table3:Topicalevaluationresultsonbankingdataset.

Figure11:Performanceofthefact-checkingrail.weuseOpenAItext-davinci-003torewritethepositiveanswertoahardnegativethatlookssim-ilartoit,butisnotgroundedintheevidence.Weconstructacombineddatasetbyequallysam-plingbothpositiveandnegativetriples.Bothtext-davinci-003andgpt-3.5-turboperformwellonthefact-checkingrailandobtainanover-allaccuracyof80%(Fig.11).Thebehaviorofthetwomodelsisslightlydifferent:whilegpt-3.5-turboisbetteratdiscoveringnegatives,text-davinci-003performsbetteronpositivesamples.G.2.3HallucinationRailEvaluatingthehallucinationrailisdifficultsincewecannotascertainthequestionsthatcanbean-sweredwithfactualknowledgeembeddedintheparametersofthelanguagemodel.Toeffectivelyquantifytheabilityofthemodeltodetecthalluci-nations,wecompilealistof20questionsbasedonafalsepremise.Forexample,onesuchquestionthatdoesnothavearightansweris:"WhenwastheunderseacityintheGulfofMexicoestablished?"Anygenerationfromthelanguagemodelapartfromdeflection(i.e.,recognizingthatthequestionisunanswerable)isconsideredafailure.Wealsoquantifythebenefitofemployingthehallucinationrailasafallbackmechanism.Fortext-davinci-003,thebaselanguagemodelisunabletodeflectpromptsthatareunanswerableandusingthehal-lucinationrailhelpsintercept70%oftheunan-swerableprompts.gpt-3.5-turboperformsverywellatdeflectingpromptsthatcannotbeansweredorhedgingitsresponsewithstatementsaboutitcouldbeincorrect.Evenforsuchpowerfulmodels,wefindthatemployingthehallucinationrailhelpsboosttheidentificationofquestionsthatarepronetoincorrectresponsesby25%.

445