NewsMet:A‘DoItAll’datasetofcontemporaryMetaphorsinNewsheadlinesRohanJoseph1,TimothyLiu2,AikBengNg2,SimonSee1,2,andSunnyRai1,31ÉcoleCentraleSchoolofEngineeringandSciences,MahindraUniversity.2NVIDIAAITechnologyCenter.3DepartmentofComputerandInformationScience,UniversityofPennsylvania.rohan18545@mechyd.ac.in,{aikbengn,timothyl,ssee}@nvidia.com,sunny.rai@seas.upenn.eduAbstractMetaphorsarehighlycreativeconstructsofhu-manlanguagethatgrowoldandeventuallydie.Populardatasetsusedformetaphorprocess-ingtaskswereconstructedfromdatedsourcetexts.Inthispaper,weproposeNewsMet,alargehigh-qualitycontemporarydatasetofnewsheadlineshand-annotatedwithmetaphor-icalverbs.Thedatasetcomprisesheadlinesfromvarioussourcesincludingpolitical,satir-ical,reliableandfake.Ourdatasetservesthepurposeofevaluationforthetasksofmetaphorinterpretationandgeneration.Theexperi-mentsrevealseveralinsightsandlimitationsofusingLLMstoautomatemetaphorprocessingtasksasfrequentlyseenintherecentliterature.Thedatasetispubliclyavailableforresearchpurposes1.1IntroductionMetaphorsarecreativecognitiveconstructsde-signedtocommunicateanideainanevocativefashion(Khaliqetal.,2021).Researchoncompu-tationalmetaphorprocessinghasexploredavarietyofquestionsrelatedtothedetectionofmetaphor-icalspeechintext(Choietal.,2021;ZhangandLiu,2022)anditsinterpretationbyreaders(Raietal.,2019;Aghazadehetal.,2022).Thetaskofmetaphorgeneration(OttolinaandPavlopoulos,2022;Lietal.,2022;Stoweetal.,2021b)hasre-centlygainedtractionduetothegrowingabilityofLLMstoforgecommonsensicalconnections.Metaphorsarehighlycreativeconstructsofhu-manlanguagethatgrowoldandeventuallydie(Raietal.,2017).ThevastmajorityofstudiesonmetaphorsintheEnglishlanguagestillrelyondatasetssuchasTroFi(BirkeandSarkar,2006),VUAMetaphorCorpus(Steenetal.,2010),andLCC(Mohleretal.,2016)thatcontainarchaicsourcetexts(SeeTableA1).Forinstance,thenews

1https://github.com/AxleBlaze3/NewsMet_Metaphor_DatasetgenreinVUAMetaphorcorpus(Steenetal.,2010)whichisderivedfromBNCBaby2hasthelatestheadlinefromtheyear1994.Deadmetaphorsinthesearchaicsourcetextsareessentiallyineffectivetrainingsamples.Moreover,theobjectofinterestthatis,metaphorsfromcon-temporaryworldtextsarelacking.Forinstance,considerthemetaphorhealin“lovehealssoul”thatdoesnotrequiremuchthoughttocomprehendver-susaphraselike“Amtrakdiningcarhealsnation”takenfromaheadlineinourdataset.Inthispaper,weproposeNewsMet,alargehigh-qualitycontemporarydatasetofnewshead-lineshand-annotatedwithmetaphoricalverbs.Metaphorsareacommonlyusedﬁgurativeconstructinnewsheadlinestobetterexplainacomplexeventorscenario.Forinstance,considerthephrases<companies,pushing,boundaries/reforms>vs<companies,pushing,mi-crochipimplants>.Themetaphoricalverbpushwithpushingimplantsisarelativelynewuse.Newsheadlinesthusprovideanevolvinglinguisticbackdropwithnewentitiestolearncontemporarymetaphoruse.Metaphorsarealsoroutinelyusedtomakeapoliticalorsocialargument.Metaphoricallanguageimprintsemotionsthatonemaynothaveanticipatedotherwiseandtherefore,metaphoricalnewscouldbeaninterestingdatasourcetoevaluatethedetectionofhyperpartisancontent.Inthispaper,wemakethefollowingcontribu-tions:•Wepresentalargedatasetofhigh-qualitycon-temporarymetaphorsfromnaturalsettingspublishedduring2017-2018.Thedatasetcom-prisesheadlinesfromsourcesidentiﬁedasre-liable,fake,biasetc.MoreinformationisprovidedinTable3.•Weinvestigatethequalityofpredictionsgen-

2http://www.natcorp.ox.ac.uk/corpus/baby/manual.pdf

10090 Findings of the Association for Computational Linguistics: ACL 2023, pages 10090–10104 July 9-14, 2023 ©2023 Association for Computational Linguistics

eratedbyLargeLanguageModels(LLMs)forthetaskofmetaphordetection,interpretationandgenerationconcerning(a)correctness,(b)likelihoodand(c)goodnessofthegeneratedpredictions.Webelievethattheproposeddatasetwillbeaninvaluableresourceforresearchersstudyingmetaphorprocessing,providingarichanddiversesetofsamples.Wefurtherbelievethatmetaphorsinnewsheadlineswillhelpunderstandandtacklethegrowingbiasandhyperpartisanindigitalme-dia.Additionally,thedatasetcouldbeutilisedtoevaluatenaturallanguageunderstandinginLLMs.2BackgroundEarlyapproachesformetaphorprocessingfocusedonanalyzingrestrictedformsoflinguisticcontextsuchasthesubject-verb-object(SVO)typegram-maticalrelation,usinghand-craftedfeatures(Bol-legalaandShutova,2013;Raietal.,2018).Later,theapproachesevolvedtocaptureimplicitrela-tionshipsinlongtextthroughwordembeddingsandlargelanguagemodels.RaiandChakraverty(2020)andTongetal.(2021)provideadetaileddiscussionontheseapproachesaswellasexist-ingdatasetsforthetasksoflinguisticmetaphordetectionandinterpretation.Metaphorgenerationresearchinparticularhasrecentlygainedtractionwithquiteafewapproachesexploitingneurallan-guagemodelsastheirunderlyingknowledgebase(Stoweetal.,2021a;Chakrabartyetal.,2021).Toevaluatemachine-generatedmetaphori-calcontent,BigBench(BIG-benchcollabo-ration,2021)proposedfourmetaphor-relatedclassiﬁcationtasks(ﬁgure_of_speech_detection,metaphor_boolean,metaphor_understandingandidentify_odd_metaphor).Thesetasksusenewlycurateddatasetsfromsourcessuchasonlineliter-atureandexistingdatasets.However,theaveragesizeofthe4datasetsmentionedis255,limitingtheirusefulnessforthetaskofevaluation.More-over,theaforementionedBigBenchtasksandsomeothernewlyproposeddatasetslikeDoDinhetal.(2018)andIMPLI(Stoweetal.,2022)usesourcetextsfromolddatasets,suchastheBNCcorpus(dated1975-1995)andSemEval2013Task5(datacollectedin2009).Thislimitstheirnoveltyasthesourcetextremainssimilartoolddatasets.Alnajjaretal.(2023)curatedmulti-modalRingThatBellcorpusofpermissivelylicensedYouTubevideosthathavehuman-authoredclosedcaptionsinEn-glishwithmetaphorsannotatedbyhumanexperts.Thisdatasethasvisualandaudiocluesthatpro-videsadditionalcontextfortextinterpretation.Existingdatasetsformetaphorinterpretation(SeeTableA2)andgeneration(SeeTableA3)areincludedintheappendixA.BizzoniandLap-pin(2018a)posedthemetaphorinterpretationtaskasanentailmentproblemandprovidedacollec-tionof200metaphoricalsentenceswithfourpara-phrases.Liuetal.(2022a)introducedacorpusofover10kcreativesentencesbasedontheWino-gradSchematotestcommonsensereasoningofmodelsforﬁgurativetext.Anexampleis“Thedinnerhastheﬂavorofarubberduck.”withtwoparaphrases.However,thetextitselfrevealsthein-herentproperty(ﬂavor)whichmakesitinappropri-ateforthetaskofmetaphorinterpretation.Zayedetal.(2020a)builtacorpusof1350verb-objectmetaphoricpairswith“dictionarydeﬁnitions”.Re-cently,Chakrabartyetal.(2022)releasedFLUTEhaving750metaphorswithtwoparaphrases.Thisdatasetishoweverbuiltusingoldsources.Tothebestofourknowledge,thereisnogold-labeldatasettoevaluatemetaphorgenerationtasks.Chakrabartyetal.(2021)provideamethodtogen-eratesilverlabelsusingaBERTmodelﬁnetunedonVUAandLCC(SeeTableA1).Theauthorsensurequalitybyconsideringsentenceswithprob-ability>0.95(Pg4252,Sec2.1).However,itisworthnotingthat83.38%ofthepredictedsampleshadprobabilities>0.95.Throughthiswork,weaimtobridgethegapforahigh-qualitycontemporarydatasetofEnglishmetaphors.Theproposeddatasethasfresh,expert-authored,thought-provokingmetaphorsthatwereusedincontemporaryworldcontexts.Additionally,wehelpaddressthegolddatascarcitychalleng-ingmetaphorinterpretationandgenerationtasksbyprovidingsamplesforallthreeusecasesi.e.detection,interpretationandgeneration.3ProposedApproachFigurativetextannotationisanon-trivialtaskthatdemandssigniﬁcantcognitiveeffortandtime.Be-lowarethekeyconcernsthatweconsideredwhiledesigningtheannotationpipeline:•Sparsity:Headlineswithmetaphorsarelikelyrare.Arandomsamplingofheadlinesformanualannotationtasksthusmayleadtoaskeweddistributionfavoringliteralheadlines.

10091

Figure1:Here,wepresentthepipelinefornewsheadlinesannotation.InSilverLabelsphase,weautomati-callypredictplausiblecandidatesfortasks(a)MetaphorDetection,(b)MetaphorGenerationand(c)MetaphorInterpretation.ThesilverlabelsaremanuallyveriﬁedandcorrectedasrequiredinGoldLabelsphase.•Subjectivity:Metaphorsarehighlysubjectivecognitiveconstructs.Itisthusimportanttocapturediverseperspectivesfrommultiplean-notatorsforthetasksnamelymetaphorinter-pretationandgeneration.•SkilledAnnotators:Humansareadeptatiden-tifyinggoodvsbadmetaphors.However,theystrugglewhenaskedtocreatemetaphors.Withoutskilledexperts,itmaybedifﬁculttothinkofgoodmetaphors.Toalleviatetheseconcerns,weusestate-of-the-artlargelanguagemodels(LLMs)forgenerationofsilvercandidates.WiththehelpofaLLM,weiden-tifypossiblymetaphoricalandliteralheadlinesthatarethenrandomlysampledformanualannotation.Theintentistoimprovethelikelihoodofseeingmetaphoricalheadlinesduringmanualannotation.WealsogenerateadiversesetofmetaphoricalandliteralcandidatesusinganLLMforhumanevalua-tion.Webelievethathumanannotatorswillbeabletoappreciatenovelinterpretationsandmetaphori-calmappingswhenpresented,andwillbequicktodiscardincorrectorabsurdconnections.Thiswillensurediversityaswellashelpusovercometheneedforhighlyskilledannotators.TheproposedannotationpipelineisillustratedinFigure1.3.1NewsHeadlinesCorpusFordatasetcreation,weusetheopensourceFakeNewsCorpus(Szpakowski,2020)thatcontainsnewsarticlesfromvarioussourcesknownforclick-bait,reliable,fakearticles.Atthetimeofdatacollection,thelatestnewsarticleinthisdatasetwasscrapedonFeb28,2018.ThepublicationdatewasidentiﬁedusingtheURLassociatedwiththenewsarticle.Weconsideredheadlinespublishedfrom2017-2018.Westartedwithasubsampleof100kheadlineshaving>7words.Thethresholdwasdecidedempiricallytoensuresufﬁcientcontext.Forthisstudy,wefocusonverbmetaphors,henceweiden-tiﬁedheadlinesthatcontainedasingleSVOtriplet3.WealsoensuredtheverbintheSVOtripletistheROOTwhenparsedusingspaCy(Honnibaletal.,2020).Forexample,considertheheadline:“JeffSessionsduetofaceDemocrats’Russiaquestionsnextweek.”4ThedetectedSVOtripletis{Sessions,face,ques-tions}andfaceistheROOTasseeninFigure2.Hencethisheadlinewillberetained.Anexampleofaheadlinethatwouldbedroppedis:“FranceThreatensBrexitDealUnlessUKTakesMoreCalaisMigrants.”5Here,thedetectedSVOis{UK,Takes,Migrants}buttheROOTobtainedafterdependencyparsingisDeal.Wethusremovethisheadlinefromtheset.Theintentbehindthisﬁlteringistoidentifythesub-jectandobjectassociatedwithaverbwhichisoftencriticalinformationwhendeterminingmetaphoric-ity.

3https://github.com/NSchrading/intro-spacy-nlp/blob/master/subject_object_extraction.py4Rawstory5Breitbart

10092

Figure2:DependencyparsetreeasgeneratedbyspaCy.Here,faceistheROOT.Dataset

Class

F1test1

F1test2

Dimbal

L

0.78

0.76

M

0.78

0.71

Dbal

L

0.71

0.58

M

0.69

0.23

Table1:PerformanceEvaluationofModelsﬁnetunedonDimbalandDbal.Thetrainvalidationsplitis90:10.LstandsforLiteralandMforMetaphorical.WerefertotheROOTasthefocusverbintherestofthepaper.Atthisstage,wehave28742uniqueheadlines.Wepickarandomsampleof15kheadlinesforthenextstagekeepinginmindthemanualeffortforannotation.3.1.1MetaphorDetectionTotacklesparsity,weﬁnetunedastate-of-the-artlargelanguagemodel,RoBERTa(Liuetal.,2019)toautomatethetaskofidentifyingpossi-blemetaphoricalheadlines.Themodelisopenlyavailableandwell-suitedforthetaskoftextclassi-ﬁcation.WeutilizedthepubliclyavailabledatasetslistedinTableA1forﬁnetuning.Thiscollectionhasatotalof62ksamplesofwhich52kweremetaphorical.WecallthissetDimbal.Toreducetheimbalancebetweentheliteralandmetaphori-calclasses,weadded29kuniqueliteralsentencesfromWikiQA(Yangetal.,2015)thatisknowntobehighlyobjective.Wealsoempiricallyveriﬁedtheliteralnessofsentencesbymanuallyinspectingarandomsampleof200.Addingthesesentencesincreasedtheliteralsamplesto39k.Wethenran-domlysampledanequalnumberofmetaphoricalsamplesfromDimbal.WecallthisnewsetDbalhavinganequalnumberofmetaphoricalandliteralsamplesi.e.39ksampleseach.Wemanuallycuratedtwobalancedtestsets(a)test1consistingofarandomsamplefromDimbal.Pleasenote,thesesampleswerenotusedfortrain-ingpurposes.(b)test2havingheadlinesfromfakenewscorpus.Bothtestsetshad50sampleseach.TheFleisskappa(Fleissetal.,1981)obtainedfortest1was0.7andCohenkappa(Cohen,1960)fortest2was0.76.Bothtestsetsareprovidedatthelink6.TheperformanceofbothmodelsonthesetestsetsissummarizedinTable1.ThemodeltrainedonDimbalsubstantiallyoutperformedtheother.Hence,weusetheRoBERTaﬁnetunedonDimbal.WedenotethismodelasMmet_det.Outofthe15kheadlinescuratedearlier,10061werepredictedasmetaphoricalbyMmet_detand4939asliteral.3.1.2CandidateSetsforMetaphorInterpretationandGenerationForthistask,wemaskthefocusverbineachhead-lineandextractthetop200candidatereplacementsgeneratedbyaLLM.Asourgoalismaskedwordreplacement,wedidnotconsiderCausalLanguageModelssuchasGPT-n.Aftermanuallyinspect-ingthequalityofcandidatesgeneratedbyMaskedLanguageModelsincludingALBERT(Lanetal.,2019),DeBERTa(Heetal.,2020)andRoBERTa,wepickedALBERTforourtask.Wedenotetheunﬁlteredinitialsetoftop200candidatesasCinit.Asapostprocessingstep,weﬁlteredcandidatesthatwerepurelynon-alphabetic.Duplicatelemmaswithinthecandidatesetswereremoved.Wealsoremovednon-verbcandidates.Thenon-verbcandidatesweredetectedbysubsti-tutingtheminplaceofthefocusverbandusingspaCy’sPOStagger(Honnibaletal.,2020).WewilldenotethisﬁlteredsetofcandidatesasCfilter.Tosegregatemetaphoricalcandidatesfromlit-eralcandidates,wereplacethefocusverbinagivenheadlinewiththecandidateverbsc∈Cfilterandpredictthemetaphoricityofthenewheadlinecon-tainingtherespectivecandidateusingMmet_det.

6https://github.com/AxleBlaze3/NewsMet_Metaphor_Dataset/tree/main/data/custom_test_sets

10093

Weonlyconsiderthetop6candidatestolimittheeffortandensurethequalityofthemanualanno-tationtaskdiscussedinSection3.2.Headlineshaving<6candidatesweredropped.Werefertothetop6candidatesoftheliteralpartitionasLinit,metaphoricalpartitionasMinitandthecombineddataasDinitrespectively.Considertheheadline,“HandlingofPoliceKillingSpursGrandJuryInquiryIntoProsecutor.”7Inthiscase,spursisthefocusverb.Here,Cinit={prompting,prompted,threatens,...,headline,catalyze,1944}.Onpassingthecandi-datesthroughMmet_det,wehaveMinit={threat-ens,requires,triggered,sends,raises,starts}andLinit={prompting,enters,begins,announces,asks,causing}Weconsideredatotalof2592originalheadlineswithcandidatesetsforgoldlabelannotations.Ofthese2592headlines,1430weremetaphoricaland1162wereliteralasperpredictionsbyMmet_det.3.2GoldLabelsAtthisstage,wehaveacollectionofnewshead-lineswithsilverlabelsthatis<Headline,Focusverb,Class(M/L),Minit,Linit>.WedesignthegoldlabelannotationprocessasillustratedinFig-ure1anddescribedbelow.•Task-1:Identifyifthegiventextismetaphor-icalorliteral.Weusetheguidelines8aspro-videdintheMetaphorIdentiﬁcationProce-dureVUUniversityAmsterdam(MIP-VU)(Pragglejaz_Group,2007)forannotation.An-notatorswereencouragedtousetheMerriam-WebsterDictionary9tohelpidentifybasicandcontextualmeaningsoflexicalunits.Ahead-lineismarkedinvalidifitcontainsﬁgurativetextthatisnotmetaphorical.Thisincludesmetonymy,idioms,sarcasmandsoon.Theannotatorsaredulyexplainedmeaningsoftheselinguisticconstructswithexamplescon-trastingthemwithmetaphoricaluse.•Task-2Identifyifthehighlightedverbismetaphorical.Thisisanimportantstepasthegenerationofmetaphoricalorliteralcan-didatesareperformedbymaskingthefocusverb.

7NewYorkTimes8http://www.vismet.org/metcor/documentation/MIPVU.html9https://www.merriam-webster.com/•Task-3Verifythesemanticappropriatenessandmetaphoricityofthemetaphoricalorlit-eralpredictionsprovidedbyLLMs(RoBERTaandALBERT)asisthecase.–Ifthesentenceandthefocusverbaremetaphorical,thenannotatorswereaskedtoidentifythecandidatesfromthegivenliteralsetwhichmakethesentencemoreliteralwhilepreservingtheorigi-nalmeaningofthesentencewhensub-stitutedinplaceofthefocusverb.WedenotethissetasLfinal.–Analogously,ifthesentenceandthefo-cusverbareliteral,thentheannotatorsarepromptedtoidentifycandidatesfromthegivenmetaphoricalcandidatesetthatmakesthesentencemoremetaphoricalwhilepreservingtheoriginalmeaningofthesentencewhensubstitutedinplaceofthefocusverb.WedenotethissetasMfinal.3.2.1AnnotationInterfaceWeusedStreamlit10anopen-sourceappframeworktobuildourannotationinterface(seeFigureA1).Inaparticularweek,eachannotatorwasgivenamaximumof100headlinestoannotate.Therewerefourquestionstobeanswered.Q1Isthesentencemetaphorical?Q2Isthefocusverbmetaphorical?Q3Whichofthecandidatesmakesthesentencemoremetaphorical/literal?Q4Whichofthecandidatessatisﬁestheaboveconditionwhilepreservingthemeaningofthesentence?Weimplementedaqualitycheck(QC)mecha-nismtoevaluatethetrustworthinessofannotators.AQCquestionistriggeredrandomlythathasadeﬁnitiveanswerforQ1andQ2.AnnotationsbyannotatorswhoperformedpoorlyontheQCmetricarediscarded.3.2.2HumanAnnotatorsAtotalof15annotatorsvolunteeredforourtask.Eachannotatorwas18-22yearsoldandanativeofIndia.Twelveannotatorsidentiﬁedthemselvesasmaleandtheremainingasfemale.Eachannotator

10https://streamlit.io/

10094

Group

Dgold

Dgold+

Invalid

314





Hm&Vm

389

1009

Hm&Vl

205



Hm&(Vm||Vl)

594

1009

=1603

Hl&Vl

611

455

=1066

=1205

=1464

=2669

Table2:DistributionofNewsMetDataset.Here,Hmindicatesmetaphoricalheadline,VmindicatesmetaphoricalverbandHl,Vlaretheliteralcounter-parts.Invalidindicatesheadlinesthatwereﬁgurativebutnotmetaphoricalsuchasidiomsandmetonymies.wasaﬂuentspeakerofEnglish.Toensurethattheannotatorshadauniformunderstandingofthetask,eachannotatorcompletedabrieftrainingbeforeundertakingthequalitychecktask.Afterqualitycheckevaluation,weselected8annotatorswhodemonstratedathoroughunderstandingofthetasktocarryouttheﬁnalsetofannotationsonstreamlit.4Results&Discussion4.1NewsMetDatasetAtotalof1519headlinescontaining795uniquefocusverbsweremanuallyannotated.TheﬁnaldistributionoflabelsisprovidedinTable2.Dgoldindicatesthesetofhand-annotatedoriginalhead-lines.Over44%oftheheadlinesirrespectiveoftypeincludingreliableweremarkedasmetaphori-cal(seeTable3).Thesetofliteralheadlinescanbefurthertrans-formedintometaphoricalheadlinesbyreplacingthefocusverbwithverbsfromtheveriﬁedcandi-datelistMfinal.Likewise,themetaphoricalhead-linescanbeconvertedtoliteralheadlinesbypick-ingcandidatesfromLfinal.Forinstance,considertheliteralheadlinebelow,‘TrumpblamesObamaagainforRussianhack-ing—butstillrefusestodoanythingaboutit’11.Here,blamesisthefocusverbandMfinal={slammed,kicks}.Ifwesubstituteslammedinplaceofblame,thetransformedheadlinewiththemetaphoricalverbisasfollows:TrumpslammedObamaagainforRussianhack-ing—butstillrefusestodoanythingaboutit.WeuseDgold+todenotethisexpandedsetofheadlines.Wethushave1009newmetaphori-

11RawstoryType

#Hm

#H(m+l)

%m

Political

213

428

49.7%Satire

85

178

47.7%Reliable

80

157

50.9%Fake

71

161

44%Bias

35

73

47.9%Clickbait

30

50

60%Conspiracy

27

52

51.9%Unknown

40

76

52.6%Others

13

30

43.3%

Total

594

1205

Table3:TypeDistributioninNewsMet.Here,#Hmindicatesthenumberofmetaphoricalheadlines.#Hm+lindicatesthetotalnumberofheadlinesinclud-ingmetaphoricalandliteral.%mindicatesthepropor-tionofmetaphoricalheadlines.ThetypelabelOthersincludestypeswithlessthan10articlessuchasHate,JunkSci,Unreliable.calheadlinesand455newliteralheadlinesinad-ditiontotheoriginal1519headlinesinourcor-pus.Thiscombinedsetof2669headlinescanbeusedfortrainingﬁgurativetextdetectionmodels.Tothebestofourknowledge,thenewsgenreinVUAMetaphorcorpus12has1451metaphoricalsentencesoutof1704.Atotalof266headlines(Hm&Vm)haveatleastoneliteralinterpretationwhereas,445head-lines(Hl&Vl)haveatleastonemetaphoricalin-terpretation.4.2QualityofSilverLabels4.2.1CorrectnessOutof1430headlinespredictedasmetaphoricalbyMmet_det,41%wereannotatedasmetaphoricalbyhumanannotators.Thatis,afalsepositiverateof59%.Likewise,27%werefalsenegativesthatis,metaphoricalheadlineswerepredictedasliteralbyMmet_det.ItisthusimportantthatﬁnetunedMetaphorDetectionmodelsareproperlyvalidatedandtestedonout-of-domaincorpora.Outof389validheadlinesconsideredformetaphorinterpretation(thatisHm&Vm),32%hadnocorrectcandidateandanother32%hadonlyonecorrectcandidate.Whereasforthetaskofmetaphorgeneration(thatisHl&Vl),27%werefoundtohavenocorrectcandidateandalmost24%wereassignedonlyonecorrectcandidatebyhumanannotators.Interestingly,metaphorinterpretation

12https://github.com/jayelm/broader-metaphor

10095

Figure3:Metaphoricityi.e.min(cos(s,c),cos(o,c))distributionforgeneratedcandidatesfromMinitandMfinal.hasahighererrorratecomparedtotherelativelydifﬁcultandcreativetaskofmetaphorgeneration.4.2.2LikelihoodofﬁndingtheﬁrstcandidateTodeterminethepositionoftheﬁrstdiscoveredcandidate,weusethecandidate’sindexpositionasinCinitbeforeanypostprocessing(asdescribedinSection3.1.2).MetaphorGeneration:89%ofthecandidatesinMinitwerefoundwithintheinterval[0,10]andthatincreasedto96.5%onstretchingtheintervalto[0,20].Incontrast,only54%ofthecandidatesinMfinalwereintheinterval[0,10]anditwentupto66.2%fortheinterval[0,20].Therewerenocandidatesfoundin27%ofthecases.Thehighper-centageofheadlineswithoutanycorrectcandidatesindeedindicatesthatMmet_detwasoverconﬁdentinlabelingmetaphors.MetaphorInterpretation:OnrepeatingthesameexperimentonLinit,94%ofthecandidateswerewithintheinterval[0,10].Thiswentupto98.7%whenweconsideredtheintervalas[0,20].However,only57%ofthecandidatesinLfinalwerelocatedwithintheintervalof[0,10].Thisincreasedto65%fortheinterval[0,20].Therewerenocandidatesfoundin32%ofthecases.Thiscouldbeattributedtothelackofanexplicitmech-anismtoﬁlteroutcandidatessemanticallyfartherfromthefocusverb.4.2.3GoodnessofPredictionThegoodnessofpredictioniscomputedonlyforthetaskofmetaphorgeneration.Theaimistoprobethemetaphoricityanddiversityofthegener-atedmetaphoricalcandidateset.

Algorithm1MeasuringDiversity

Input:H←headline,fv←focus_verb,MinitOutput:clusters,diversity1:clusters←{φ}.setofclustersofsimilarwords2:index←03:foriinrange(len(Minit))do4:ci←Minit[i]5:H←H.swap(fv,ci)6:synset1←lesk(H,ci,verb)7:forjinrange(i+1,len(Minit)do8:cj←Minit[j]9:H←H.swap(fv,cj)10:synset2←lesk(H,cj,verb)11:sim_score←synset1.lch_sim(synset2).Thresholdisdecidedempirically.Here,itis1.712:ifsim_score>thresholdthen13:ifci∈clustersthen14:clusters[find(ci)].union(cj)15:elseifcj∈clustersthen16:clusters[find(cj)].union(ci)17:else18:clusters[index++].union(ci,cj)19:endif20:endif21:endfor22:endfor23:diversity=|clusters|24:returndiversity,clusters

Metaphoricity:Weleveragethenotionofincongruity(Wilks,1975)todeterminethemetaphoricityofthegeneratedcandidateswithre-specttotheirsubject(s)andobject(o)inagivenheadline.Wemakeasimpleassumptionthatametaphoricalcandidatec∈Minitisincongru-ouseitherwithitssubjectorobjectinthehead-line.Alowersimilarityindicatesahigherdis-tancebetweenthecandidatewordanditssur-roundingcontextandtherefore,highermetaphoric-ity(YuandWan,2019).Wethusconsiderthefunctionmin(cos(s,c),cos(o,c))whendetermin-ingmetaphoricity.WeusethecosinesimilarityfunctionfoundintheGensimlibrary(ˇReh˚uˇrekandSojka,2010)andGloVe-300dembeddings(Penningtonetal.,2014)toestimatethedissimilarityforourexperiments.WeplotthedistributionofcandidatesinMinitinFigure3.Theplotdoesreﬂectapatternforlowerco-sinesimilarityandthereforehighermetaphoricity,whichisintunewiththehand-annotatedcandi-datesinMfinal.Wealsonotethatcandidateshav-inglowmin(cos(s,c),cos(o,c))aremorelikelytobemarkedmetaphoricalbyhumanannotatorscomparedtoothermachine-generatedcandidates.Diversity:AmetaphorisamappingbetweenaTARGETdomainandSOURCEdomain.Consider

10096

Headline(focusverb)

Clustersi

diversity

FarCry5’:CoopMissionhasamassiveproblemwithmissionprogress

{confronts,faces}1,{creates,causes}2,{ﬁnds}3,{tackles}4

4

Wait...PeterStrzokDiscussed‘Insur-ancePolicy’AgainstTrumpPresidencyWithAndrewMcCabe?

{sells,buying,traded}1,{wants}2,{gets}3,{considers}4

4

CouldOneofTheseFourScreenplaysWintheOscar?

{steal,snatch,take}1,{grab}2,{snare}3,{scoop}4

4

Sens.CoryBooker,AlFrankenandElizabethWarrenproposethattheU.S.‘preventgenocide’

{demandedask}1,{insist,require,recommend}2,{suggest}3

3

Table4:AsubsetofHeadlineswithclustersanddiversityasgeneratedbyAlgorithm1.Here,iindicatestheclusternumber,diversityisthenumberofclusters.themetaphoricalphrase,‘Mycardrinksgasoline.’.Here,themappingisCARISANIMATEanddrinkisthelinguisticmanifestationfromthedomainAN-IMATE.Inanattempttoquantifythevarietywithinthecandidateset,wemeasurethediversity.Thatis,thenumberofclustersformedaftergroupingcon-ceptuallysimilarwords.ThisisanapproximationtocounttheuniqueSOURCEDOMAINSinMinit.OuralgorithmforclusteringconceptuallysimilarwordsisprovidedinAlgorithm1.Theinputis{headline,focusverb,Minit}.Theobjectiveistogroupcandidateshavingstrongis-arelationship.UsingLeskAlgorithm(Lesk,1986),weﬁrstdisambiguatethewordsensetoidentifytherightWordNet(Fellbaum,2010;LoperandBird,2002)synsetforacandidatewordc∈Minitasinlines3-6.UsingLeacock-Chodorowsimilarity(Leacocketal.,1998),wethendeterminethesim-ilaritybetweenthesynsetsofanytwocandidatesandaccordinglyclusterasinlines7-18.Weem-piricallydecidedthesimilaritythresholdas1.7tobeclusteredtogether.WeprovideafewexamplesinTable4.Forinstance,wordssuchasselling,buyingandtradingareessentiallyrepresentinganoverlappingidea.Likewise,create,causealsohaveasharedmeaning.Onmanualanalysisoftheclus-teredsets,wefoundthemtobecoherentandvalid.Outof611headlines,wefoundthat238(38.9%)hadascoreof6fordiversitythatis,everycandi-datewordwasinitsowncluster(#clusters=6asthereareonlysixcandidates).161(26.3%)had5,115(18.8%)had4,65(10.6%)had3,26(4.2%)had2andonly6(0.9%)hadone.Thisisanencour-agingresultthatindeedsupportstheuseofLLMstogeneratediversesetsforthetaskofmetaphorModel

A

P

R

F1

Mmet_det

0.54

0.70

0.35

0.46MDimbal+Dgold+

0.61

0.68

0.57

0.62

Table5:BaselinePerformanceEvaluationforthetaskofMetaphorDetection.RoBERTamodelﬁnetunedonDgold+inadditiontoDimbalperformssigniﬁcantlybetterthanMmet_det.generation.4.3BaselinePerformanceWecomparedtheperformanceofRoBERTatrainedonDimbal+Dgold+withMmet_det(RoBERTatrainedonDimbal(SeeSec3.1.1)).WesplitDgold+into80%train,10%validationand10%test.Whiledoingso,weensuredthetestsetTgold+of546sampleshadnooverlapwiththetrainandvalidationsetsintermsofheadlinesandtheirre-spectivetransformations.TheperformanceonTgold+issummarizedinTa-ble5.MDimbal+Dgold+showcasedaperformanceimprovementof7%inaccuracy,16%inF1scoreand22%inrecall.WealsoperformedMcNemar’sstatisticalsigniﬁcancetestandobtainedastatisticof57withp<0.01indicatingthegaininperfor-manceisstatisticallysigniﬁcant.5ConclusionInthispaper,weproposedNewsMetformedfromcontemporarynewsheadlines,hand-annotatedwithmetaphoricalverbs.Thesamplesareprovidedwithmetaphoricalandliteralinterpretations.Thisdatasetisusefulforbuildingandevaluatingauto-matedsystemstodetect,interpretaswellasgen-eratemetaphors.Ouranalysiscautionsagainstthe

10097

blinduseofﬁne-tunedmetaphordetectionmodelstoannotatenewcorpora.However,LLMscouldbeofgreathelpincuratingdiversemetaphoricalcandidatesets.Theproposeddatasethasavarietyofnewssourcessuchasreliableandbiasthatcanbeusefulinunderstandingtheroleofmetaphorsinnewsframingandhyperpartisancontent.Machinetranslationofﬁgurativetextisanunderexploredre-searcharea.Theliteralcandidatesassociatedwithmetaphoricalsamplescanbeusedtoautomaticallyevaluatethequalityoftranslations.ItwouldalsobeinterestingtoevaluateLLMsforthetaskofgen-eratingculturallycoherentmetaphorsintranslatednewsheadlines.LimitationsTheproposeddatasetisannotatedforverbmetaphorsinparticular.However,otherlexicalunitsincludingadjectivesandadverbsshouldalsobestudiedinordertotrulyunderstandtheroleofmetaphorsinnews.Itisimportanttoexaminethediversityofthegeneratedideaswhenperformingmetaphorgeneration.Inthisstudy,weproposedasimpleapproachtoclusterwordsusingWordNet.However,themetricisfarfromperfectandcanbeimproved.Forthetaskofcandidategeneration,weperformedwordmaskingtogeneratemetaphoricalandliteralsubstitutesaswewerecuriousabouttheabilityofLLMstogeneraterelevantmetaphoricalmappingswhilepreservingtheunderlyingseman-ticidea.Directsubstitutionofmetaphoricalcandi-datesresultedinsyntacticallyincoherentsentencesinafewcases.Itmaybebettertoparaphrasethesentenceafterselectingthemetaphoricalmapping(OttolinaandPavlopoulos,2022).EthicalConcernsandBroaderImpactWecreatedthedatasetfromapubliclyavailablenewsheadlinesdataset.Thisensuresthatdataisfreefrom(a)anonymityconcerns,(b)obscenitiesand(c)anystereotypingorbias.Asthetaskiscognitivelyintensive,weonlyassignedatmost150headlinestoeachannotator.AllannotatorsweredulyacknowledgedandappreciatedbyNvidiaAITechnologyCenterfortheircontribution.Theorig-inaldatasetofnewsheadlinesistheunderApacheLicense2.0.Wearethuspermittedtomodifyandredistributeit.Generatingmetaphorscarriesconcernsduetotheimplicitpotentialtocraftmisleadingtext.Theusageofmetaphorshasbeenshowntoresonateemotionallywithreaders(CitronandGoldberg,2014).Thisshouldnotbeaconcernwithourdataasweonlyreleasegeneratedcandidatesthatpreservetheunderlyingsemanticmeaningofthesourceheadline.ReferencesEhsanAghazadeh,MohsenFayyaz,andYadollahYaghoobzadeh.2022.Metaphorsinpre-trainedlan-guagemodels:Probingandgeneralizationacrossdatasetsandlanguages.InProceedingsofthe60thAnnualMeetingoftheAssociationforComputa-tionalLinguistics(Volume1:LongPapers),pages2037–2050,Dublin,Ireland.AssociationforCom-putationalLinguistics.KhalidAlnajjar,MikaHämäläinen,andShuoZhang.2023.Ringthatbell:Acorpusandmethodformul-timodalmetaphordetectioninvideos.BIG-benchcollaboration.2021.Beyondtheimitationgame:Measuringandextrapolatingthecapabilitiesoflanguagemodels.Inpreparation.JuliaBirkeandAnoopSarkar.2006.Aclusteringap-proachfornearlyunsupervisedrecognitionofnonlit-erallanguage.In11thConferenceoftheEuropeanChapteroftheAssociationforComputationalLin-guistics,pages329–336,Trento,Italy.AssociationforComputationalLinguistics.YuriBizzoniandShalomLappin.2018a.Predictinghu-manmetaphorparaphrasejudgmentswithdeepneu-ralnetworks.InProceedingsoftheWorkshoponFigurativeLanguageProcessing,pages45–55.YuriBizzoniandShalomLappin.2018b.Predictinghumanmetaphorparaphrasejudgmentswithdeepneuralnetworks.InProceedingsoftheWorkshoponFigurativeLanguageProcessing,pages45–55,NewOrleans,Louisiana.AssociationforComputationalLinguistics.DanushkaBollegalaandEkaterinaShutova.2013.Metaphorinterpretationusingparaphrasesextractedfromtheweb.PLOSONE,8(9):1–10.TuhinChakrabarty,ArkadiySaakyan,DebanjanGhosh,andSmarandaMuresan.2022.Flute:Figu-rativelanguageunderstandingthroughtextualexpla-nations.InProceedingsofthe2022ConferenceonEmpiricalMethodsinNaturalLanguageProcessing,pages7139–7159.TuhinChakrabarty,XuruiZhang,SmarandaMuresan,andNanyunPeng.2021.MERMAID:Metaphorgenerationwithsymbolismanddiscriminativede-coding.InProceedingsofthe2021ConferenceoftheNorthAmericanChapteroftheAssociationforComputationalLinguistics:HumanLanguageTech-nologies,pages4250–4261,Online.AssociationforComputationalLinguistics.

10098

MinjinChoi,SunkyungLee,EunseongChoi,HeesooPark,JunhyukLee,DongwonLee,andJongwukLee.2021.MelBERT:Metaphordetectionviacon-textualizedlateinteractionusingmetaphoricaliden-tiﬁcationtheories.InProceedingsofthe2021Con-ferenceoftheNorthAmericanChapteroftheAsso-ciationforComputationalLinguistics:HumanLan-guageTechnologies,pages1763–1773,Online.As-sociationforComputationalLinguistics.FrancescaMMCitronandAdeleEGoldberg.2014.Metaphoricalsentencesaremoreemotionallyengag-ingthantheirliteralcounterparts.Journalofcogni-tiveneuroscience,26(11):2585–2595.J.Cohen.1960.ACoefﬁcientofAgreementforNom-inalScales.EducationalandPsychologicalMea-surement,20(1):37.OanaDavid,EllenDodge,JHong,EliseStickles,andESweetser.2014.Buildingthemetanetmetaphorrepository:Thenaturalsymbiosisofmetaphoranal-ysisandconstructiongrammar.InThe8thInterna-tionalConstructionGrammarConference(ICCG8),pages3–6.Erik-LânDoDinh,HannahWieland,andIrynaGurevych.2018.Weedingoutconventionalizedmetaphors:Acorpusofnovelmetaphorannota-tions.InProceedingsofthe2018ConferenceonEmpiricalMethodsinNaturalLanguageProcessing,pages1412–1424,Brussels,Belgium.AssociationforComputationalLinguistics.ChristianeFellbaum.2010.Wordnet.InTheoryandapplicationsofontology:computerapplications,pages231–243.Springer.JosephLFleiss,BruceLevin,MyungheeChoPaik,etal.1981.Themeasurementofinterrateragree-ment.Statisticalmethodsforratesandproportions,2(212-236):22–23.PengchengHe,XiaodongLiu,JianfengGao,andWeizhuChen.2020.Deberta:Decoding-enhancedbertwithdisentangledattention.MatthewHonnibal,InesMontani,SoﬁeVanLan-deghem,andAdrianeBoyd.2020.spacy:Industrial-strengthnaturallanguageprocessinginpython.MohammedAbdulKhaliq,RohanJoseph,andSunnyRai.2021.#covidiswarand#vaccineisweapon?covid-19metaphorsinindia.InProceedingsofthe18thInternationalConferenceonNaturalLanguageProcessing(LongPapers),pages431–438.GeorgeLakoffandMarkJohnson.1980.Metaphorsweliveby.ZhenzhongLan,MingdaChen,SebastianGoodman,KevinGimpel,PiyushSharma,andRaduSoricut.2019.Albert:Alitebertforself-supervisedlearn-ingoflanguagerepresentations.ClaudiaLeacock,MartinChodorow,andGeorgeAMiller.1998.Usingcorpusstatisticsandwordnetre-lationsforsenseidentiﬁcation.ComputationalLin-guistics,24(1):147–165.MichaelLesk.1986.Automaticsensedisambiguationusingmachinereadabledictionaries:howtotellapineconefromanicecreamcone.InProceedingsofthe5thannualinternationalconferenceonSystemsdocumentation,pages24–26.YuchengLi,ChenghuaLin,andFrankGuerin.2022.Nominalmetaphorgenerationwithmultitasklearn-ing.InProceedingsofthe15thInternationalConfer-enceonNaturalLanguageGeneration,pages225–235,Waterville,Maine,USAandvirtualmeeting.AssociationforComputationalLinguistics.EmmyLiu,ChenCui,KennethZheng,andGrahamNeubig.2022a.Testingtheabilityoflanguagemod-elstointerpretﬁgurativelanguage.arXivpreprintarXiv:2204.12632.EmmyLiu,ChenxuanCui,KennethZheng,andGra-hamNeubig.2022b.Testingtheabilityoflanguagemodelstointerpretﬁgurativelanguage.InProceed-ingsofthe2022ConferenceoftheNorthAmeri-canChapteroftheAssociationforComputationalLinguistics:HumanLanguageTechnologies,pages4437–4452,Seattle,UnitedStates.AssociationforComputationalLinguistics.YinhanLiu,MyleOtt,NamanGoyal,JingfeiDu,Man-darJoshi,DanqiChen,OmerLevy,MikeLewis,LukeZettlemoyer,andVeselinStoyanov.2019.Roberta:Arobustlyoptimizedbertpretrainingap-proach.EdwardLoperandStevenBird.2002.Nltk:Thenatu-rallanguagetoolkit.arXivpreprintcs/0205028.SaifM.Mohammad,EkaterinaShutova,andPeterDTurney.2016.Metaphorasamediumforemotion:Anempiricalstudy.InProceedingsoftheFifthJointConferenceonLexicalandComputationalSeman-tics(*Sem),Berlin,Germany.MichaelMohler,MaryBrunson,BryanRink,andMarcTomlinson.2016.IntroducingtheLCCmetaphordatasets.InProceedingsoftheTenthIn-ternationalConferenceonLanguageResourcesandEvaluation(LREC’16),pages4221–4227,Portorož,Slovenia.EuropeanLanguageResourcesAssocia-tion(ELRA).GiorgioOttolinaandJohnPavlopoulos.2022.Metaphoricalparaphrasegeneration:Feedingmetaphoricallanguagemodelswithliteraltexts.BradPasanek.2015.Themindisametaphor:Browsethedatabase.JeffreyPennington,RichardSocher,andChristopherManning.2014.GloVe:Globalvectorsforwordrepresentation.InProceedingsofthe2014Confer-enceonEmpiricalMethodsinNaturalLanguage

10099

Processing(EMNLP),pages1532–1543,Doha,Qatar.AssociationforComputationalLinguistics.Pragglejaz_Group.2007.Mip:Amethodforiden-tifyingmetaphoricallyusedwordsindiscourse.Metaphorandsymbol,22(1):1–39.SunnyRaiandShampaChakraverty.2020.Asurveyoncomputationalmetaphorprocessing.ACMCom-putingSurveys(CSUR),53(2):1–37.SunnyRai,ShampaChakraverty,DevendraKTayal,andYashKukreti.2017.Softmetaphordetectionusingfuzzyc-means.InInternationalConferenceonMiningIntelligenceandKnowledgeExploration,pages402–411.Springer.SunnyRai,ShampaChakraverty,DevendraKTayal,andYashKukreti.2018.Astudyonimpactofcon-textonmetaphordetection.TheComputerJournal,61(11):1667–1682.SunnyRai,ShampaChakraverty,DevendraKTayal,DivyanshuSharma,andAyushGarg.2019.Under-standingmetaphorsusingemotions.NewGenera-tionComputing,37(1):5–27.RadimˇReh˚uˇrekandPetrSojka.2010.SoftwareFrame-workforTopicModellingwithLargeCorpora.InProceedingsoftheLREC2010WorkshoponNewChallengesforNLPFrameworks,pages45–50,Val-letta,Malta.ELRA.http://is.muni.cz/publication/884893/en.EkaterinaShutova.2010.Automaticmetaphorinter-pretationasaparaphrasingtask.InHumanLan-guageTechnologies:The2010AnnualConferenceoftheNorthAmericanChapteroftheAssociationforComputationalLinguistics,pages1029–1037,LosAngeles,California.AssociationforComputa-tionalLinguistics.GerardJ.Steen,AlettaG.Dorst,J.BerenikeHerrmann,AnnaKaal,TinaKrennmayr,andTrijntjePasma.2010.AMethodforLinguisticMetaphorIdentiﬁ-cation:FromMIPtoMIPVU.JohnBenjamins.KevinStowe,NilsBeck,andIrynaGurevych.2021a.Exploringmetaphoricparaphrasegeneration.InProceedingsofthe25thConferenceonComputa-tionalNaturalLanguageLearning,pages323–336.KevinStowe,TuhinChakrabarty,NanyunPeng,SmarandaMuresan,andIrynaGurevych.2021b.Metaphorgenerationwithconceptualmappings.InProceedingsofthe59thAnnualMeetingoftheAssociationforComputationalLinguisticsandthe11thInternationalJointConferenceonNaturalLan-guageProcessing(Volume1:LongPapers),pages6724–6736,Online.AssociationforComputationalLinguistics.KevinStowe,PrasetyaUtama,andIrynaGurevych.2022.IMPLI:InvestigatingNLImodels’perfor-manceonﬁgurativelanguage.InProceedingsofthe60thAnnualMeetingoftheAssociationforCompu-tationalLinguistics(Volume1:LongPapers),pages5375–5388,Dublin,Ireland.AssociationforCom-putationalLinguistics.MaciejSzpakowski.2020.Fakenewscorpus.Avail-ableathttps://github.com/several27/FakeNewsCorpus.XiaoyuTong,EkaterinaShutova,andMarthaLewis.2021.Recentadvancesinneuralmetaphorprocess-ing:Alinguistic,cognitiveandsocialperspective.InProceedingsofthe2021ConferenceoftheNorthAmericanChapteroftheAssociationforComputa-tionalLinguistics:HumanLanguageTechnologies,pages4673–4686.YuliaTsvetkov,LeonidBoytsov,AnatoleGershman,EricNyberg,andChrisDyer.2014.Metaphordetec-tionwithcross-lingualmodeltransfer.InProceed-ingsofthe52ndAnnualMeetingoftheAssociationforComputationalLinguistics(Volume1:LongPa-pers),pages248–258,Baltimore,Maryland.Associ-ationforComputationalLinguistics.YorickWilks.1975.Apreferential,pattern-seeking,se-manticsfornaturallanguageinference.Artiﬁcialin-telligence,6(1):53–74.YiYang,Wen-tauYih,andChristopherMeek.2015.WikiQA:Achallengedatasetforopen-domainques-tionanswering.InProceedingsofthe2015Con-ferenceonEmpiricalMethodsinNaturalLanguageProcessing,pages2013–2018,Lisbon,Portugal.As-sociationforComputationalLinguistics.ZhiweiYuandXiaojunWan.2019.Howtoavoidsen-tencesspellingboring?towardsaneuralapproachtounsupervisedmetaphorgeneration.InProceed-ingsofthe2019ConferenceoftheNorthAmericanChapteroftheAssociationforComputationalLin-guistics:HumanLanguageTechnologies,Volume1(LongandShortPapers),pages861–871.OmniaZayed,JohnPhilipMcCrae,andPaulBuite-laar.2020a.Figuremeout:agoldstandarddatasetformetaphorinterpretation.InProceedingsofthe12thLanguageResourcesandEvaluationConfer-ence,pages5810–5819.OmniaZayed,JohnPhilipMcCrae,andPaulBuite-laar.2020b.Figuremeout:Agoldstandarddatasetformetaphorinterpretation.InProceedingsoftheTwelfthLanguageResourcesandEvaluationCon-ference,pages5810–5819,Marseille,France.Euro-peanLanguageResourcesAssociation.ShenglongZhangandYingLiu.2022.Metaphordetec-tionvialinguisticsenhancedSiamesenetwork.InProceedingsofthe29thInternationalConferenceonComputationalLinguistics,pages4149–4159,Gyeongju,RepublicofKorea.InternationalCom-mitteeonComputationalLinguistics.

10100

AAppendixA.1ExistingdatasetsDataset

Source

TimePeriod

Tsvetkovetal.(2014)

Web

2014LCC(Mohleretal.,2016)

ClueWeb09anddebatepoliticsforum

2009-unknownTroFi(BirkeandSarkar,2006)

WSJ

1987-1989MasterMetaphorList(LakoffandJohnson,1980)

publishedbooks,papersandresearchseminars

1991editionMetaNet(Davidetal.,2014)

Original

2013-2016Mohammadetal.(2016)

Wordnet

NotSpeciﬁed.VUAMC(Steenetal.,2010)

BNC-Baby

1975-1995

TheMindisaMetaphor(Pasanek,2015)

VariousSources

aim:1660-1819Grothe13

VariousSources

BC-21stcentury

WikiQA(Yangetal.,2015)

Wikipedia

NotSpeciﬁed

TableA1:MetaphorDetection:DatasetsusedforﬁnetuningRoBERTaDataset

Source

TimePeriod

#M

#NM

LabelTypes

Shutova(2010)

Mixed(BNCcorpus)

2010

761



GoldBizzoniandLappin(2018b)

Original(Crowdsourced)

2018

200



GoldZayedetal.(2020b)

Twitter

2020

1300



GoldLiuetal.(2022b)

Handwrittenmetaphors+similes(Crowdsourced)

2022

10256



Gold

TableA2:ExistingDatasetsfortheMetaphorInterpretationTaskDataset

Source

TimePeriod

#M

#NM

LabelTypes

MERMAID(Chakrabartyetal.,2021)

GutenbergPoetry

1991-2016

90000



Silver

TableA3:ExistingDatasetsusedfortheMetaphorGenerationtaskA.2ModelParametersA.2.1RoBERTaNo.ofParameters:WeusetheRoBERTabasecheckpoint(125Mparameters)14.NoofEpochs:Weﬁnetunedthemodelfor7epochsandsavethebestmodelbasedonvalidationaccuracy.TrainingTime:2hoursTraininghyperparameters:Weusepopularparametersthatis,learningrate:2e−5,dropoutas0.3andAdamWastheoptimizer.A.2.2ALBERTWemakeuseofthepre-trainedalbert-xxlarge-v215checkpointwithoutﬁnetuning.No.ofParameters:223Mparameters

14https://huggingface.co/roberta-base15https://huggingface.co/albert-xxlarge-v2

10101

A.2.3HardwareConﬁgurationWemadeuseofGooglecolab16toﬁne-tuneRoBERTaandmakepredictions.TheserviceprovidesavarietyofsingleGPUinstances(commonlyNvidiaT4orP100)andassignsonebasedonavailability.TotalGPUhoursequatedtoapproximately8.A.3StreamlitAnnotationInterfaceTheinterfaceisprovidedinFigureA1.

FigureA1:InterfaceforAnnotation.Humanannotatorsusedthisinterfaceto(a)verifythemetaphoricityofpredictedverbmetaphorand(b)identifysemanticallyappropriatedliteralormetaphoricalcandidatesasapplicable.

16https://colab.research.google.com/

10102

ACL2023ResponsibleNLPChecklist

AForeverysubmission:(cid:3)3A1.Didyoudescribethelimitationsofyourwork?Section5(cid:3)3A2.Didyoudiscussanypotentialrisksofyourwork?Section6(cid:3)3A3.Dotheabstractandintroductionsummarizethepaper’smainclaims?AbstractandSection1(cid:3)7A4.HaveyouusedAIwritingassistantswhenworkingonthispaper?Leftblank.B(cid:3)3Didyouuseorcreatescientiﬁcartifacts?Section3(cid:3)3B1.Didyoucitethecreatorsofartifactsyouused?Onﬁrstmentionofeachresourceacrossthepaper(varioussections)(cid:3)3B2.Didyoudiscussthelicenseortermsforuseand/ordistributionofanyartifacts?Section3andSection6(cid:3)3B3.Didyoudiscussifyouruseofexistingartifact(s)wasconsistentwiththeirintendeduse,providedthatitwasspeciﬁed?Fortheartifactsyoucreate,doyouspecifyintendeduseandwhetherthatiscompatiblewiththeoriginalaccessconditions(inparticular,derivativesofdataaccessedforresearchpurposesshouldnotbeusedoutsideofresearchcontexts)?Section6wediscussredistributionofthedataset(cid:3)7B4.Didyoudiscussthestepstakentocheckwhetherthedatathatwascollected/usedcontainsanyinformationthatnamesoruniquelyidentiﬁesindividualpeopleoroffensivecontent,andthestepstakentoprotect/anonymizeit?Weuseexistingpubliclyavailablenewsheadlines(cid:3)3B5.Didyouprovidedocumentationoftheartifacts,e.g.,coverageofdomains,languages,andlinguisticphenomena,demographicgroupsrepresented,etc.?InSection3,Section6,A(cid:3)3B6.Didyoureportrelevantstatisticslikethenumberofexamples,detailsoftrain/test/devsplits,etc.forthedatathatyouused/created?Evenforcommonly-usedbenchmarkdatasets,includethenumberofexamplesintrain/validation/testsplits,astheseprovidenecessarycontextforareadertounderstandexperimentalresults.Forexample,smalldifferencesinaccuracyonlargetestsetsmaybesigniﬁcant,whileonsmalltestsetstheymaynotbe.InSection3C(cid:3)3Didyouruncomputationalexperiments?Section3(cid:3)3C1.Didyoureportthenumberofparametersinthemodelsused,thetotalcomputationalbudget(e.g.,GPUhours),andcomputinginfrastructureused?AppendixA1

TheResponsibleNLPChecklistusedatACL2023isadoptedfromNAACL2022,withtheadditionofaquestiononAIwritingassistance.

10103

(cid:3)3C2.Didyoudiscusstheexperimentalsetup,includinghyperparametersearchandbest-foundhyperparametervalues?Section3andA1(cid:3)3C3.Didyoureportdescriptivestatisticsaboutyourresults(e.g.,errorbarsaroundresults,summarystatisticsfromsetsofexperiments),andisittransparentwhetheryouarereportingthemax,mean,etc.orjustasinglerun?Section3,Section4(cid:3)3C4.Ifyouusedexistingpackages(e.g.,forpreprocessing,fornormalization,orforevaluation),didyoureporttheimplementation,model,andparametersettingsused(e.g.,NLTK,Spacy,ROUGE,etc.)?Section3,Section4D(cid:3)3Didyouusehumanannotators(e.g.,crowdworkers)orresearchwithhumanparticipants?Section3(cid:3)3D1.Didyoureportthefulltextofinstructionsgiventoparticipants,includinge.g.,screenshots,disclaimersofanyriskstoparticipantsorannotators,etc.?Section3(cid:3)3D2.Didyoureportinformationabouthowyourecruited(e.g.,crowdsourcingplatform,students)andpaidparticipants,anddiscussifsuchpaymentisadequategiventheparticipants’demographic(e.g.,countryofresidence)?Section3(cid:3)3D3.Didyoudiscusswhetherandhowconsentwasobtainedfrompeoplewhosedatayou’reusing/curating?Forexample,ifyoucollecteddataviacrowdsourcing,didyourinstructionstocrowdworkersexplainhowthedatawouldbeused?Section6,Wedidnotcollectdatafrompeople.Ourannotatorsannotatedexistingavailabledata(nopersonaldatainvolved)andunderstoodthetask.(cid:3)D4.Wasthedatacollectionprotocolapproved(ordeterminedexempt)byanethicsreviewboard?Notapplicable.Wearelabellingexistingpublicdatasetswithnohumanorsocialexperimentationinvolved.(cid:3)3D5.Didyoureportthebasicdemographicandgeographiccharacteristicsoftheannotatorpopulationthatisthesourceofthedata?Section3,fulldetailswillbeavailableafterthedouble-blindreviewperiod

10104