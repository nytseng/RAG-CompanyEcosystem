JON FORTT:  I am here at Nvidia headquarters in Santa Clara with the CEO of the world’s most valuable company and the CEO and president of the world’s most valuable private company, Jensen Huang of Nvidia, Sam Altman, and Greg Brockman of OpenAI. So let’s dive right into the news. Jensen, Nvidia is making a $100 billion investment in OpenAI and working together to build out, I think you’re saying 10 gigawatts of capacity over several years. The investment is going to come with the gigawatts, one at a time. You’re telling me, you guys, as quickly as you guys can get it done. Jensen, first of all, set the stage. Why?

JENSEN HUANG:  This is the biggest A.I. infrastructure project in history. This is the largest computing project in history. Well, the reason for that is because computing demand is going through the roof for OpenAI. You know, ChatGPT is the single most revolutionary A.I. project in history. It’s being used everywhere, every industry, every country. Every person practically that I know uses ChatGPT. The computing demand is going through the roof. And so this partnership is about building an A.I. infrastructure that enables A.I. to go from the labs into the world. This is about the A.I. industrial revolution arriving. It’s a very big deal.

FORTT:  Yeah. A hundred billion dollars, a lot of money. Sam, Greg, you guys are used to dealing with a lot of money in big projects. So, Sam, I think it was just eight months and a day ago the initial Stargate announcement talking about the overall move that OpenAI is making in building out this capacity. Where does this fit?

SAM ALTMAN:  So, as Jensen said, building this infrastructure is critical to everything we want to do. Without doing this, we cannot deliver the services people want. We can’t keep making better models. And now that we really see what’s on the near-term horizon of how good the models are getting, the new use cases that are being enabled, what people want to do, this is like the fuel that we need to drive improvement, to drive better models, to drive revenue, everything. So this is helping us get to a world, along with our partners at Stargate, Microsoft, Oracle, where we can build out increasing amounts of infrastructure to deliver on what the world is demanding out of these services. There’s like no partner but Nvidia that could do this at this kind of scale, this kind of speed. It’s really, like, quite, quite incredible. But this will expand on the Stargate ambitions and let us push further and further. We have found every step along the way that we did not quite set our sights big enough, given the market demand. So this will help us push towards that next level. The compute constraints that the whole industry has been – and our company, in particular, have been terrible. We’re so limited right now in the services we can offer. There’s so much more demand than what we can do. And as we look forward another year or two years, if you have –  let’s say it takes 10 gigawatts of compute or five gigawatts of compute, you could choose one of two things. You could choose to cure cancer by doing a bunch of –  having A.I. do a bunch of research, or you could choose to offer free education to everybody on Earth. No one wants to make that choice. And so increasingly, as we see this, the answer is just much more capacity so that we can serve the massive needs and opportunity with this.

FORTT:  Greg, one way of measuring that demand is the number of users that OpenAI has. ChatGPT says somewhere between 700 and 800 million. How quickly are you growing? What’s the technology that you guys need to bring to bear from Nvidia included in order to satisfy that?

GREG BROCKMAN:  Yes, so 700 million, growing extremely quickly. I think that ChatGPT has grown from nothing to that scale and continues to grow faster than any product in history. And, really, the reason we were able to make this breakthrough and serve it to the extent that we have is by leveraging Nvidia’s platform. Like, we have worked together very closely since Jensen actually hand-delivered a server to us back in 2016. We were just doing some math earlier. I think that this deal is really for a billion times more computational power than that initial server. And so we’re able to actually create new breakthroughs, new models to be able to actually solve problems, like create cures for diseases, and to actually be able to empower every individual in business because we will be able to reach the next level of scale.

FORTT:  Jensen, step back for me. I mean, a few days –  you’re all over the place, literally. I mean, you’re in the U.K. I saw the white bow tie and all that, the tux.

ALTMAN:  You looked very nice, Jensen.

FORTT:  Here you look very nice. But you’re also doing a lot of investments. The Intel investment announced last week quite a bit smaller than this one, but seems significant also, because it’s weaving Nvidia technology in the PCN data center level in a way that perhaps it wasn’t before. Where do these kinds of investments fit in? How do you think about the value of the ecosystem to Nvidia?

HUANG:  The Intel partnership is about recognizing that accelerated computing and A.I.’s day has arrived. Remember, general purpose computing was invented practically 60 years ago. And for the last 60 years, we have been following that basic blueprint, that basic architecture to build the ecosystem, the computing use of the world. And so, all of a sudden, accelerated computing’s time has come. And we’re fusing, if you will, the Intel architecture with the Nvidia architecture to bring them into the world of accelerated computing and A.I. So that’s what that partnership’s about. This partnership, I mean, this is monumental in size. There’s never been an engineering project, a technical project, of this complexity and this scale ever. And it really just says that A.I. was in the early adopter phase in the labs, and, finally, it’s breaking out into just about every single industry, every single use case we can imagine. It is very soon where every single word, every single interaction, every single image, video that we experience on –  through computers will somehow have been reasoned through or referenced by or generated by A.I. It’s going to be touched by A.I. somehow. So all of our computing experiences throughout the day everywhere in every industry will be powered by A.I. This first 10 –  this is the first 10 gigawatts. Surely, it sounds like an enormous undertaking, but there’s no question that A.I. is transformational for every industry. But the important thing is, the A.I. infrastructure will be everywhere and will power computing experiences for everyone every day. And it’s going to be just everywhere.

FORTT:  Sam, it seems like the two most valuable companies in the world, Nvidia at number one over $4 trillion – about $4.25 trillion last time I checked today – Microsoft just under $4 trillion, are going to be major investors in OpenAI. How should we understand the governance, the influence that these companies have over OpenAI, where those lines are and even, you know, investment size-wise, where that’s going to net out?

ALTMAN:  We’re thrilled to have them both as partners. They’re passive investors. Our nonprofit and board are in control, but the ecosystem is really important to us. Nvidia and Microsoft are two of our most critical partners and have been from the very front, from the very beginning. And having them so aligned with our success is, I think, great for us, hopefully great for them too.

FORTT:  Greg, where does Nvidia fit along with all of the other infrastructure providers? Oracle –  you guys kind of touched Oracle and the stock went up, even though the name wasn’t attached to it. When they reported earnings and their guidance, a lot of people were looking over at OpenAI. Where do these different technology infrastructure players fit in terms of importance in the amount of capacity that you need?

BROCKMAN:  Well, look, the project that we’re trying to do is something that, as Jensen was saying, is bigger than any infrastructure build-out that’s ever been done. It’s much larger than the Apollo program, for example. And so we’re going as big as we can with the biggest partners in the world. Nvidia is a core strategic partner for our build-out. There’s just no one who could build as fast or as big as they are going to be able to accelerate us to be able to do. We are working together with Oracle to do a lot of the infrastructure builds with SoftBank and Stargate, to be able to actually do a bunch of that work as well. We’re starting to expand into just trying to figure out every single way that we can actually get this compute to the world. But there’s really been no partner like Jensen, like Nvidia. And it’s just been a very, very special partnership for more than a decade now. And we’re moving into a next phase together.

HUANG:  Now, one of the things that’s really important to say is that -- and Sam and Greg hinted at it -- this is additive. This project, 10 gigawatts of A.I. infrastructure, is additive to everything that has been announced and contracted. Remember, they have contracted huge amounts of capacity through Azure, through OCI, through CoreWeave. And all of that is powered by Nvidia. And we’re really delighted working with all of these partners. And that’s going to continue to grow. This is additive, incremental on top of that, which just kind of puts it in perspective, the scale of A.I. computing that’s needed for the world.

FORTT:  Well, I’m clearly not asking you –

HUANG:  The demand is just exponential.

FORTT:  Yeah. To say anything different from what’s already been included in the financials that you have given or the guidance that you have given. But this is an announcement that’s breaking right here on CNBC. Has this been factored into the numbers that you have given Wall Street up to this point?

HUANG:  This is additive to everything that we have spoken about so far. It’s pretty incredible.

FORTT:  We’re also talking about A.I. infrastructure for the world. One of the headlines last week had to do with China and how they’re dealing or not dealing with Nvidia. When you look at where this capacity is getting built out and the global use that it’s going to have, how do you think about the way different regions, the way different countries are going to tap into that and how that affects Nvidia’s competitiveness?

HUANG:  Well, President Trump was clear about this. And you have heard me say this before, that we want the world to be built on the American tech stack. And the American tech stack, the A.I. computing stack includes chips, infrastructure, models and applications. We have every, every reason to believe that the United States should lead in every single one of those layers. And in doing so, we want the world to be built on top of American chips. We want American infrastructure, American models, and for the world to integrate with American applications. And we ought to diffuse this capability as fast as possible because the world is racing to bring A.I. out to the world. And so I think the need to build A.I. infrastructure all around the world, this is just the beginning. Notice, most of the infrastructure we’re – infrastructure conversations we have been having are largely located in the United States. But we’re going to see A.I. infrastructure built in Europe and in the southern parts of the world. You’re going to be, right, Southeast Asia. All over the world, we’re going to be building A.I. infrastructur

FORTT:  Sam, there was a DeepSeek moment several months ago. The market kind of freaked out about what this means for infrastructure, for capacity, for expense. What was the legacy of that? Given the moment that we’re in right now, this $100 billion investment Nvidia is making in you, clearly, you see value in these chips, or you wouldn’t need that kind of money for that kind of equipment. What does that mean? How has the way the conversation around A.I. models has shifted affected the way that you guys are looking at the build-out?

ALTMAN:  Two thoughts about this. First of all, I think most of the world still thinks of A.I. as what ChatGPT can do. You know, it’s a better version of Web search or it helps me with some small tasks here and there. A.I. has moved an incredible distance. A.I. is now outperforming humans at the most difficult intellectual competitions we have. For the first time with GPT-5, you’re starting to see scientists saying A.I. is making novel discoveries, small ones, but real ones. And so there’s – I think there’s this huge mismatch in the world of what most people think A.I. can do and what the frontier of A.I. can do. And so when DeepSeek came out, I think people had this brief freak-out. I think maybe your stock went way down in one day, and people were just like, oh, this is like the end. People really want to predict the end of the compute scaling somehow. And then it turned out that people need a lot of A.I., and they need a lot of the frontier A.I. And so it is totally true that the cost per unit of intelligence will keep falling and falling and falling, and we think that’s great. We will be able to offer services like ChatGPT, more of it, cheaper, the whole thing. But on the other side, the frontier of A.I., the maximum intellectual capability, is going up and up, and that enables more and more use, and a lot of it. So there’s this huge overhang that the world, I think, does not yet grasp of where the models already are today, and when you throw a lot of inference computer, then what they can do for you, that is totally different than ChatGPT or generate an image or whatever. And so I think that was really missed in the DeepSeek moment, and why we want to do this. It’s that there’s – the models are at this point like actually quite capable for things far beyond what most people use them for in ChatGPT, and the world is just catching up with that. Second thing, we throw around these numbers, 10 gigawatts, $100 billion, and there’s a few syllables here and there. We’re – it’s like a Monday morning. We’re all kind of like low energy. We got a lot of stuff we got to go do and stressed about the day ahead. But the –

HUANG:  And we have already had a pretty long day.

(LAUGHTER)

ALTMAN:  We have had a long day. But the magnitude –

FORTT:  This deal, yes, I mean, I flew out here not knowing exactly who I was talking to, when this came together. So, yes, thank you, but yeah.

ALTMAN:  For sure. Thanks for taking a flier on that.

(LAUGHTER)

ALTMAN:  But the magnitude of the scale of this project, $100 billion is a small dent in it. And the numbers are also like, they’re missing the story of what this amount of infrastructure is capable of doing. Like, 10 gigawatts of compute, again, easy to throw around numbers like that. But the amount of work it takes to build that out, the size and scale of these like multisquare-mile, gigantic things and the complexity at every level of the supply chain, and then what that amount of brainpower, which does not exist today, can do already today, what it will do as the models get better, like, this is the real deal. This is the thing people have been waiting for. They talk about A.I. or when it’s going to do this and when it’s going to do that. Like, the stuff that will come out of this super brain will be remarkable in a way I think we don’t really know how to think about yet.

FORTT:  A hundred billion is a small dent. Now you sound like President Trump.

(LAUGHTER)

BROCKMAN:  One way to contextualize the scale of what we’re talking about and the compute scarcity of the world that we’re heading towards, you know, ChatGPT today, you talk to it, it gives you answers. But clearly you want an agent that’s going to go do work for you proactively while you’re asleep, be able to organize your calendar or go try to work on projects for you. And so you really want every person to be able to have their own dedicated GPU, right? So you’re talking on order of 10 billion GPUs we’re going to need. This deal we’re talking about, it’s for millions of GPUs. Like, we’re still three orders of magnitude off of where we need to be. So we’re doing our best to provide compute availability, but we’re heading to this world where the economy is powered by compute, and it’s going to be a compute scarce one.

FORTT:  So, Sam –

HUANG:  You know, Jon, remember, this new project that we’re talking about, 10 gigawatts or roughly four million, five million GPUs, that’s approximately in one project what we shipped all year this year, OK, and twice as much as last year, twice as much as the year before that. And so that kind of puts it in perspective. This is a giant project. And yet –

FORTT:  And we don’t yet know how many years to amortize that over, sort of, but it’s –

HUANG:  Well, we just need – OpenAI – I mean, OpenAI’s the fastest growing software company in history.

ALTMAN: We will see how fast we can build.

FORTT:  So, about the infrastructure, we were talking about data centers, but I also want to talk to you about the edge. And I guess Sam or Greg, this could be either of you. Apple had their big launch of selling iPhones last week. A lot of people thought, oh, they’re behind on A.I. They’re trying to push this idea that these phones, because the chips they have in them are A.I.-ready. And, of course, they’re talking to you guys. Are these part of the infrastructure that you need? What should the world understand about the role of the Edge and devices like this?

ALTMAN:  Totally. This is where – there’s this important idea, which is most of the world thinks about A.I. as ChatGPT. And yet A.I. capability has moved far beyond. So, for the kind of chat with ChatGPT about most stuff, you will be able to do a lot of that on your phone. And we think that’s great. We released an open-source model called GPT-OSS recently that can run on a laptop or a phone. And it’s incredible to me what you can do on a device. It’s gone way further than I thought. And we’d love to see a lot of that move to the Edge. Curing cancer, like an A.I. that thinks really hard and cures cancer, that will need the big data center. But for, like, the sort of standard ChatGPT queries, we hope we can push a lot of that to the Edge.

FORTT:  So what’s the significance of these platforms, whether it’s from Apple, whether it’s from the likes of a Qualcomm, in being able to provide a standard platform for you guys, for other partners, for other application providers to build A.I.-driven applications on top of, which are going to drive some of this demand that we have been talking about here?

BROCKMAN:  I think you need all of it, right? I think that, no matter how much gets built, we are still going to be in this world of compute scarcity. And every time there’s a new compute platform, new availability of this kind of computational power, that it’s possible to design new algorithms, new methods, new models, new products that are able to deliver benefits to everyone. And so you should expect that you will see this whole ecosystem of models from us and from everyone else that is able to take advantage of what’s out there. It’s a little bit like when the App Store first came out, suddenly, people started creating apps and filling that platform because there was this new availability, this new way of building. And I think we’re heading towards a platform shift that’s going to be much more significant than anything in history.

FORTT:  Another potential, either roadblock or opportunity is talent, right? You have got to have the right people to build this stuff, to design this stuff, et cetera. Immigration is a part of that. Jensen, there have been some moves, some announcements over the past few days about that. How does that position the U.S., maybe the H-1B issue and the extra charge on top of that, how does that position the U.S. in terms of competitiveness? What are your thoughts on where we need to go?

HUANG:  We want all the brightest minds that come to the United States. And, remember, immigration is the foundation of the American dream. And we represent the American dream. And so, I think immigration is really important to our company and it’s really important to our nation’s future. And I’m glad to see President Trump making the moves he’s making.

FORTT:  What kind of policy needs do we have from your perspective at OpenAI?

ALTMAN:  We need to get the smartest people in the country. And streamlining that process and also sort of aligning financial incentives seems good to me.

FORTT:  How far are we from yet another big announcement, right, about the capital needs and how you hope to fulfill that?

ALTMAN:  You should expect a lot from us in the coming months. We are really – there are three things that OpenAI has to do well. We have got to do great A.I. research. We have to build these products that people really want to use. And we have to figure out how to do this unprecedented infrastructure challenge and build-out, which there’s chips, there’s power, there’s buildings, there’s lots of pieces that go into that. And that latter category is going to be my big focus in the coming month, and we have very ambitious goals. So, we will have a lot to say.

FORTT:  Jensen, the next big catalyst that you see on the horizon? I mean, A.I. is what’s driving so much of the market and the imagination right now of economies across the world.

HUANG:  Look, we saw in the last five, 10 years A.I. move from generative to reasoning to now thinking models. Went from text to multimodal. It is very clear that there will be a persistent A.I. connected to every device to be everything that’s out there. It could be a persistent A.I. connected to the car, connected to smart glasses, connected to the phone as you mentioned, connected to human or robots, and robots of all different sizes and shapes. And all of that is just beginning. None of it exists today, and yet everything’s around the corner. That’s how exciting this is.

ALTMAN:  Yes.

HUANG:  We’re literally going to connect intelligence to every application, to every use case, to every device. And we’re just at the beginning of that. That’s the reason why we need such gigantic infrastructure. And this is the first 10 gigawatts. I assure you of that.

FORTT:  Well, I’m looking at the CNBC app, and there’s Nvidia’s stock right now. We can’t see OpenAI’s stock yet.

ALTMAN:  Oh, yes.

FORTT:  But call me when we can. Scott and the Halftime crew, back to you on this breaking news from Nvidia headquarters here in Santa Clara.

